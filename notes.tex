%
\documentclass{report}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amscd}
\usepackage{fullpage}
\usepackage{braket}
\usepackage{dsfont}
\usepackage{mdframed}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{axiom}{Axiom}
\newtheorem{example}[theorem]{Example}
\newtheorem{exercise}{Exercise}[section]

\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{note}{Note}

\newcommand{\FR}[2]{\frac{#1}{#2}}
\newcommand{\PFR}[2]{\left(\frac{#1}{#2}\right)}
\newcommand{\SFR}[2]{\sqrt{\frac{#1}{#2}}}

\newcommand{\mc}{\mathcal}
\newcommand{\lam}{\lambda}
\newcommand{\vphi}{\varphi}
\newcommand{\om}{\omega}
\newcommand{\Om}{\Omega}
\newcommand{\gam}{\gamma}
\newcommand{\sg}{\sigma}
\newcommand{\di}{\partial}
\newcommand{\ddi}[2]{\FR{\partial {#1}}{\partial {#2}}}
\newcommand{\hp}{\hat p}
\newcommand{\ha} { a}
\newcommand{\hb} { b}
\newcommand{\hbd} { b^\dagger}
\newcommand{\had}{ a^\dagger}
\newcommand{\iden}{\mathds{1}}

\newcommand{\elaborate}{{\color{blue} \textbf{Elaborate.}}}
\newcommand{\CHECK}{{\color{blue} \textbf{CHECK}}}

\DeclareMathOperator{\bC}{\mathbb{C}}
\DeclareMathOperator{\bR}{\mathbb{R}}
\DeclareMathOperator{\bP}{\mathbb{P}}
\DeclareMathOperator{\bN}{\mathbb{N}}
\DeclareMathOperator{\bZ}{\mathbb{Z}}
\DeclareMathOperator{\cA}{\mathcal{A}}
\DeclareMathOperator{\cB}{\mathcal{B}}
\DeclareMathOperator{\cC}{\mathcal{C}}
\DeclareMathOperator{\cD}{\mathcal{D}}
\DeclareMathOperator{\cF}{\mathcal{F}}
\DeclareMathOperator{\cH}{\mathcal{H}}
\DeclareMathOperator{\cI}{\mathcal{I}}
\DeclareMathOperator{\cJ}{\mathcal{J}}
\DeclareMathOperator{\cL}{\mathcal{L}}
\DeclareMathOperator{\fg}{\mathfrak{g}}
\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\im}{Im}
\DeclareMathOperator{\re}{Re}
\DeclareMathOperator{\Ad}{Ad}
\DeclareMathOperator{\Sp}{Sp}
\DeclareMathOperator{\SO}{SO}
\DeclareMathOperator{\GL}{GL}
\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\Aut}{Aut}
\DeclareMathOperator{\so}{so}

\begingroup
    \makeatletter
    \@for\theoremstyle:=definition,remark,plain\do{%
        \expandafter\g@addto@macro\csname th@\theoremstyle\endcsname{%
            \addtolength\thm@preskip\parskip
            }%
        }
\endgroup

\edef\restoreparindent{\parindent=\the\parindent\relax}
\usepackage{parskip}
\restoreparindent

\setcounter{chapter}{-1}

\title{Quantum Field Theory\\Fall 2015 Seminar Notes}
\author{Anton Borissov, Henry Liu}
\date{\today}

\begin{document}

\maketitle

\tableofcontents

\chapter{Review}

Let's review some notation and concepts from quantum mechanics and
special relativity. Note that not all these concepts carry over to
quantum field theory. For example, in quantum mechanics, we are always
working with states within some Hilbert space, but in quantum field
theory, there is no suitable Hilbert space.

\section{Quantum Mechanics}

The fundamentals of quantum mechanics have had almost a century to be
formalized, and indeed they have been! Here we give a somewhat
axiomatic presentation of QM.

\begin{axiom}[States]
  Let $\cH$ be a (complex) Hilbert space. Its projectivization
  $\bP\cH$ is the {\bf state space} of our system.
  \begin{itemize}
  \item An element of $\cH$, i.e. a state, is called a {\bf ket}, and
    is written $\ket{x}$.
  \item An element of $\cH^*$, i.e. a functional, is called a {\bf
      bra}. The bra associated to $\ket{x}$ (under the identification
    $\cH \cong \cH^*$ given by the inner product) is denoted $\bra{x}$.
  \end{itemize}
  Consequently, $\braket{x|x} = \|x\|^2$, which we usually want to
  normalize to be $1$.

  Note that the symbol inside the ket or bra is somewhat arbitrary.
  For example, the states of a quantum harmonic oscillator are written
  $\ket{n}$, for $n \in \bN$.
\end{axiom}

Given a space of states, we can look at the operators that act on the
states. These operators must be unitary, so that normalized states go
to normalized states. 

\begin{axiom}[Observables]
  To every classical observable (i.e. property of a system) is
  associated a quantum operator, called an {\bf observable}.
  Observables are (linear) self-adjoint operators whose (real!)
  eigenvalues are possible values of the corresponding classical
  property of the system. For example,
  \begin{itemize}
  \item $\hat{H}$ is the {\bf Hamiltonian} of the system, which
    classically represents the ``total energy'' (kinetic + potential)
    in the system,
  \item $\hat{x}$ is the {\bf position operator},
  \item $\hat{p}$ is the {\bf momentum operator}.
  \end{itemize}
  The convention in QM is that observables are denoted by symbols with
  hats on them. The process of ``moving'' from a classical picture of
  a system to a quantum picture by making classical observables into
  operators is called {\bf quantization}, because the possible values
  of the observables are often quantized, i.e. made discrete, whereas
  previously they formed a continuum.
\end{axiom}

A classical observable is simple: it is just a function $f$ defined on
the classical phase space, so in order to make a measurement of the
observable, we simply apply $f$ to the current state of the system.
In QM it is not as simple, in most part due to its inherently
probabilistic nature. But it is still straightforward.

\begin{axiom}[Measurement]
  If $\hat{A}$ is the observable and $\hat{A}\ket{k} = a_k\ket{k}$,
  i.e. $\ket{k}$ is an eigenstate with eigenvalue $a_k \in \bR$, then
  the probability of obtaining $a_k$ as the value of the measurement
  on $\ket{\psi}$ is $|\braket{k|\psi}|^2$. But not only is the
  outcome probabilistic, the state of the system after the measurement
  is $\ket{k}$. In other words, {\bf measurement is projection}. This
  is fundamental to QM and cannot be emphasized enough.

  There are some conventions for position and momentum eigenstates.
  Since $\hat{x}$ and $\hat{p}$ are conventional symbols to use for
  position and momentum respectively, the states $\ket{x}$ and
  $\ket{p}$ are position and momentum eigenstates with eigenvalues $x$
  and $p$ respectively.
\end{axiom}

What about states that we don't measure? What are they doing as time
passes? We need to specify the {\bf dynamics} of our system, and this
is where the quantum analog of the Hamiltonian comes into play.

\begin{axiom}[Dynamics]
  The time-evolution of the state $\ket{\psi}$ is specified by the
  Hamiltonian $\hat{H}$ of the system, and is given by the {\bf
    Schr\"odinger equation}
  $$ i\hbar \frac{d\ket{\psi}}{dt} = \hat{H}\ket{\psi}, $$
  where $\hbar$ is Planck's constant (later we will be working in
  units where $\hbar = 1$). Note that we can solve this first-order ODE:
  $$ \ket{\psi(t)} = \exp(-i\hat{H}t)\ket{\psi(0)}. $$
  The operator $U(t) = \exp(-i\hat{H}t)$ is known as the {\bf
    time-evolution operator}.
\end{axiom}

That's it! There are some quick consequences of these axioms we should
explore before moving on. First, although measurement is
probabilistic, we often work with states whose observables tend to
take on values clumped around a certain value, which corresponds to
the classical value of that observable for the system. So given a
state $\ket{\psi}$ and observable $\hat{A}$, it is reasonable to
define the {\bf expectation value} and {\bf standard deviation}
$$ \braket{\hat{A}} = \braket{\psi|\hat{A}|\psi}, \qquad \Delta \hat{A} = \sqrt{\braket{\hat{A}^2} - \braket{\hat{A}}^2}. $$

\begin{proposition}[Heisenberg's uncertainty principle]
  Let $\hat{A}$ and $\hat{B}$ be self-adjoint operators. Then
  $$ \Delta \hat{A} \Delta \hat{B} \ge \frac{1}{2}\left|\braket{[\hat{A}, \hat{B}]}\right|. $$
\end{proposition}

\begin{proof}
  Note that the variance can also be written 
  $$ \Delta \hat{A} = \braket{\psi|(\hat{A} - \braket{A})^2|\psi}. $$
  Without loss of generality, assume
  $\braket{\hat{A}} = \braket{\hat{B}} = 0$, since we can shift
  $\hat{A}$ and $\hat{B}$ by constants without affecting
  $\Delta \hat{A}$ and $\Delta \hat{B}$. Then an application of
  Cauchy-Schwarz (using braket notation) gives
  $$ \Delta \hat{A} \Delta \hat{B} = \|\hat{A}\ket{\psi}\| \|\hat{B}\ket{\psi}\| \ge \left|\braket{\psi|\hat{A}\hat{B}|\psi}\right|. $$
  Now note that if $z = \braket{\psi|\hat{A}\hat{B}|\psi}$, then
  $|z| \ge |\im z| = |z - z^*|/2$. Hence
  $$ \left|\braket{\psi|\hat{A}\hat{B}|\psi}\right| \ge \frac{1}{2}\left|\braket{\psi|\hat{A}\hat{B}|\psi} - \braket{\psi|\hat{A}\hat{B}|\psi}^*\right| = \frac{1}{2}\left|\braket{\psi|\hat{A}\hat{B} - (\hat{A}\hat{B})^\dagger|\psi}\right| = \frac{1}{2}\left|\braket{\psi|[\hat{A}, \hat{B}]|\psi}\right|, $$
  where the last equality follows from the observables being
  self-adjoint:
  $(\hat{A}\hat{B})^\dagger = \hat{B}^\dagger\hat{A}^\dagger =
  \hat{B}\hat{A}$.
\end{proof}

For example, if we have a particle in $\bR^n$, the Hilbert space
underlying the state space is $\cH = L^2(\bR^n)$, and the position and
momentum operators are given by
$$ \hat{x}: \psi(x) \mapsto x\psi(x), \quad \hat{p}: \psi(x) \mapsto -i\hbar\nabla\psi(x). $$
A short calculation gives the {\bf fundamental commutation relation}
between $\hat{x}$ and $\hat{p}$:
$$ [\hat{x}, \hat{p}] = i\hbar, $$
which we interpret as saying that we cannot know both the exact
position and exact momentum of a particle at the same time.

\section{Special Relativity}

\setcounter{axiom}{0}

Special relativity describes the structure of spacetime. It says that
spacetime is $\bR^{1+3}$, known as {\bf Minkowski space} (as opposed
to $\bR^4$, Euclidean space) and equipped with the {\bf Minkowski
  metric}
$$ ds^2 = c^2 dt^2 - dx^2 - dy^2 - dz^2 $$
where $c$ is the speed of light (later we will work in units where
$c = 1$). As with QM, there is a nice axiomatic presentation of SR,
which is essentially just the following axiom.

\begin{axiom}[Lorentz invariance]
  The fundamental laws of physics must be invariant under isometries
  of Minkowski space. These isometries form the {\bf Poincar\'e group}
  $\bR^{1+3} \rtimes \SO(1,3)$. The subgroup $\SO(1,3)$ is known as
  the {\bf Lorentz group}; its elements are called {\bf Lorentz
    transformations}, and are precisely the isometries leaving the
  origin fixed.
\end{axiom}

So any Hamiltonian, Lagrangian, or physical expression we write down
from now on had better be Lorentz invariant (we will usually work
locally with nicely-behaved objects that are automatically invariant
under the full Poincar\'e group if they are Lorentz invariant).

Along with special relativity, Einstein introduced his {\bf summation
  notation} for tensors:
\begin{itemize}
\item Components of (contravariant) vectors $\vec{v}$ are written with
  superscripts, i.e. $\vec{v} = v^1 e_1 + \cdots + v^n e_n$, and those
  of (covariant) covectors with subscripts;
\item An index which appears both as a subscript and a superscript is
  implicitly summed over, i.e. $\vec{v} = v^i e_i$;
\item Unbound indices (the ones not summed over) must appear on both
  sides of an equation.
\end{itemize}
For example, $T^{\mu \alpha} = g^{\mu \nu} T^\alpha_\nu$ demonstrates
contraction with the metric tensor. When there is superscript that
should be a subscript, or vice versa, the metric tensor is implicitly
being used to raise and lower indices.

There are several conventions regarding Einstein's summation notation.
Spacetime variables are indexed by Greek letters, e.g. $\mu$ or $\nu$,
which run from $0$ to $3$, while space-only variables are indexed by
Roman letters, e.g. $i$ or $j$, which run from $1$ to $3$. Given a
$4$-vector $v = v^\nu e_\nu$, we let $\vec{v} = v^i e_i$ be the
space-only component, and $v^2$ generally denotes $v^\mu v_\mu$
whereas $\vec{v}^2$ generally denotes $v^i v_i$.


\chapter{Klein-Gordon Field}

In this chapter, we will look at our first quantum field, called the
Klein-Gordon field. This field arises from the Klein-Gordon equation
$$ (\partial^2 + m^2)\phi = 0, $$ which came about as an attempt to
make the Schr\"odinger equation compatible with special relativity,
where time and space coordinates can be mixed by Lorentz
transformations. Klein and Gordon first proposed it to describe
wavefunctions of relativistic electrons, but that interpretation
turned out to have some serious problems; nowadays we know it instead
describes a quantum field. Although it is meaningless classically
(i.e. it does not describe any classical system worth investigating),
we will begin by examining Klein-Gordon fields classically, and then
putting them through a process called canonical quantization to obtain
the quantum Klein-Gordon field.

\section{Why Fields?}

Before we begin, let's motivate why we want to look at fields instead
of wavefunctions. Why complicate things if we can do relativistic QM
with wavefunctions, instead of QFT with quantum fields?

%   Words of wisdom from Landau and Lifshitz: uncertainty principle implies
%   impossibility of wavefunction (see IV~\S~1, Landau Peierls~1931);
%   second quantization -- pick complete basis, count the number of
%   particles in each state..

    Volume 1 of Steven Weinberg's \emph{Quantum Theory of Fields} is
    devoted to answering this question. A discussion of scattering
    experiments lead him to the $S$-matrix, and then to the local behaviour
    of experiments (which he calls the cluster decomposition principle),
    and then using Lorentz invariance, fields just practically fall out.
    Weinberg does a really good job of convincing us that QFT in some form
    or another really must exist if we assume Lorentz invariance and
    unitarity.
%   First, he analyzes scattering
%   experiments and introduces us to the arena of the multiparticle Hilbert
%   space and the main player, the $S$-matrix. Next, using the cluster
%   decomposition principle, he justifies why a Hamiltonian must be written
%   as a sum of creation and annihilation operators. This cluster
%   decomposition principle makes precise what we mean by ``experiments at
%   large distances between one another are uncorrelated.'' Moreover, ``this
%   cluster decomposition principle plays a crucial part in making field
%   theory inevitable.'' (Weinberg Vol 1) This approach is very appealing
%   for it justifies why fields are important without citing the
%   ``problems'' of previous theories.
%
%   Miscelleanous remarks from the wisdom bank of Weinberg:
%   \begin{itemize}
%       \item {\color{red}``The structure and properties of any quantum field are
%           dictated by the representations of the homogenous Lorentz group
%       under which it transforms.''}
%       \item Free fields $\leftrightarrow$ trivial
%           representation, causal vector $\leftrightarrow$ 4-vector
%           representation, Dirac fields $\leftrightarrow$ dirac
%           representation, etc.
%   \end{itemize}

Peskin and Schroeder give a slightly different motivation, one that is
closer to the historical reason of why fields were introduced. There
are three main factors at play here.
\begin{itemize}
\item
  Single particle relativistic wave functions have unavoidable
  negative energy eigenstates. As an example, we can look at the Dirac
  equation. The Dirac equation comes from forcing the Schr\"odinger
  equation $i(d\Psi/dt) = \hat{H}\Psi$ to be Lorentz invariant. As it
  stands, it is first-order in time, but second-order in space.
  Suppose instead that
  $$ \hat{H} = \frac{1}{i} \alpha^j \partial_j + m\beta. $$
  Since $E^2 = \vec{p}^2 + m^2$, we want $\hat{H}^2 = -\nabla^2 + m^2$,
  which gives
  $$ \alpha^j \alpha^k + \alpha^k \alpha^j = 2\delta^{jk}, \quad
  \alpha^j \beta + \beta \alpha^j = 0, \quad \beta^2 = 1. $$
  Hence $\{\alpha^1, \alpha^2, \alpha^3, \beta\}$ are not scalars, but
  instead are the generators of a Clifford algebra; we take their
  simplest representation as matrices, which is as $4 \times 4$
  complex matrices
  $$ \alpha^j = \begin{pmatrix} 0 & \sigma_j \\ \sigma_j &
    0 \end{pmatrix}, \quad \beta = \begin{pmatrix} I & 0 \\ 0 &
    -I \end{pmatrix}, $$
  where $\sigma_j$ are the Pauli matrices. Now compute in momentum-
  space that
  $$ \widehat{H\psi}(\vec{p}) = (-i \vec{p} \cdot \vec{\alpha} +
  m\beta) \hat{\psi}(\vec{p}) = \begin{pmatrix} mI & \vec{p} \cdot
    \vec{\sigma} \\ \vec{p} \cdot \vec{\sigma} & -mI \end{pmatrix}
  \hat{\psi}(\vec{p}), $$
  and a straightforward calculation shows that $\hat{H}$ has
  eigenvalues $\pm \sqrt{\vec{p}^2 + m^2}$. In particular, the energy
  can be negative!

  Dirac attempted to resolve this issue by appealing to the Pauli
  exclusion principle and positing that there existed a whole ``sea of
  negative-energy states'' that were already occupied. Consequently,
  the holes in this sea would be antiparticles. This makes sense until
  we realize that that a particle falling into a negative-energy state
  would represent particle-antiparticle annihilation, but the Dirac
  equation is supposed to be modeling a single particle (an electron,
  actually). So philosophical issues aside, there are technical issues
  here. The field viewpoint will allow us to view particles as
  excitations of some field, and antiparticles of different types of
  excitations of the same field, but the key here is that these
  excitations all have positive energy, regardless of whether they
  represent particles or antiparticles. We will investigate this later
  on, when we see the Dirac field (which will contain the first
  non-trivial example of antiparticles).

\item
  $E=mc^2$ allows for particles to be created at high energies, and
  $\Delta E \Delta t = \hbar$ allows for virtual particles. This
  indicates we should really be looking at multi-particle instead of
  single-particle theories. While we can obtain multi-particle
  theories simply by looking at the tensor product of single-particle
  state spaces, the quantum mechanics arising from this construction
  do not permit the creation and annihilation of particles. We can't
  ``destroy'' or ``create'' a wavefunction; it exists for all time and
  space. Instead, the field viewpoint allows us to view particles as
  excitations of a field, which we can easily create or destroy.
  
\item
  Wavefunctions and quantum mechanics don't care about special
  relativity. In particular, there is obvious causality violation in
  quantum mechanics! Set $H = \FR{\hp^2}{2m}$ to be the free
  Hamiltonian, and let's compute the probability amplitude for
  propagation between two points $x_0$ and $x$ in spacetime:
  \begin{align*}
    U(t) &= \braket{\vec x|e^{-iHt}|\vec x_0}\\ &= \int
    \FR{d^3p}{(2\pi)^3} \braket{\vec
      x|e^{-i(p^2/2m)t}|p}\braket{p|x}\\ &= \int \FR{d^3p}{(2\pi)^3}
    e^{-i(p^2/2m)t}e^{i\vec p\cdot (\vec x-\vec x_0)}\\ &=
    \PFR{m}{2\pi i t}^{3/2} e^{im(\vec x-\vec x_0)^2/2t}
  \end{align*}
  This last quantity is non-zero, even for $x$ and $x_0$ that may be
  space-like separated, e.g. $x$ inside the light cone, and $x_0$
  outside it, which, in principle, allows faster-than-light transfer
  of information.

  It is not clear immediately how field theory will help us here. But
  we will see that by rigorously enforcing Lorentz invariance when we
  write down field dynamics, the causality violation problem magically
  disappears.
\end{itemize}

Another important reason we want to do QFT is because, well, the
theory predicts the outcome of numerous experiments to very high
accuracy. In the end, physics is about constructing models: the fact
that your model is giving good predictions is very strong evidence
that it should be adopted, or at least seriously considered as a
foundational theory. In particular, quantum electrodynamics (QED),
which describes electromagnetism, is something we will see very soon
that has been very well tested and agrees very well with experiments,
up to the limits of what we can experimentally measure.
    
\section{Elements of Classical Field Theory}

Before we embark on the long journey through QFT, we need to review
some tools from classical field theory first. This serves not only as
a review, but as motivation for many calculations and objects we will
be examining in the QFT world.

\subsection{Lagrangian Field Theory}

\begin{itemize}
\item Fundamental quantity in Lagrangian field theory is the action $S$.
In high school, the Lagrangian is a function of time,
positions, and velocities of a system: $L(t,x(t),\dot x(t))$. The action
is given by $S = \int dt\, L$.
Fields can also be described in a Lagrangian formalism, for instance by
considering every point in space-time as a ``particle'' that wiggles back
and forth with the amplitude of wiggling characterizing the strength of the
field.

Let $\vphi : M \to \bR$, define a Lagrangian \emph{density} $\mc
L(t,\vphi,\di_\mu \vphi)$, the honest Lagrangian $L = \int d^3x \mc L$, and
finally define the action: \[ S = \int dt\, L = \int d^4x \mc L \]

\begin{mdframed}
    Four-vector notation:
    \begin{itemize}
        \item Greek letters $\mu,\nu,\ldots \in \{0,1,2,3\}$
        \item Roman letters $i,g,\ldots \in \{1,2,3\}$.
        \item $x^\mu = (x^0,x^1,x^2,x^3)$
        \item Signature $(+---)$
        \item $\eta_{\mu\nu} = \mathrm{diag}(1,-1,-1,-1)$
        \item $\di_\mu f = \FR{\di f}{\di x^\mu} = (\di_0 f,\di_1 f,\di_2
            f,\di_3 f)$.
    \end{itemize}
\end{mdframed}

\item Extremize the action. Let $\delta f = f(\vphi+\xi) - f(\vphi)$.
    \begin{align*}
        0 = \delta S &= \int d^4 x \left( \ddi{\mc L}{\vphi}\delta\vphi
        +\ddi{\mc L}{(\di_\mu \vphi)}
        \underbrace{\delta(\di_\mu}_{\text{commute}}\vphi)\right)\\
        &= \int d^4 x \left[ \ddi{\mc L}{\vphi}\delta\vphi
        + \di_\mu \left(  \ddi{\mc L}{(\di_\mu\vphi)}\delta\vphi \right)
    - \di_\mu \left(\ddi{\mc L}{(\di_\mu\vphi)}\right)\delta\vphi \right]
    \end{align*}
    By Stokes' theorem, we can break this integral up into two parts, one
    of which is called the boundary term. Taking a variation that is fixed
    along the boundary means $\delta\vphi \equiv 0$ on the boundary which
    means that the boundary term does not contribute to $\delta S$.
    Moreover, if we take $\delta S = 0$ for every variation, then we obtain
    the Euler Lagrange equations:
    \[ \di_\mu \left( \ddi{\mc L}{(\di_\mu \vphi)} \right) - \ddi{\mc
    L}{\vphi} = 0 \]

    \begin{remark}
        The Lagragian formalism is useful for relativistic dynamics because
        all expressions are chosen to Lorentz invariant.
    \end{remark}
    \end{itemize}
\subsection{Hamiltonian Field Theory}
    \begin{itemize}
\item Introducing this makes the transition to the quantum theory easier.
\item High school Hamiltonian formalism: 
    $p = \ddi{L}{\dot q},H=\sum p\dot q-L$.
\item Pretend that $\vec x$ enumerates points on the lattice of space-time:
    \begin{align*}
        p(\vec x) = \ddi{\mc L}{\dot\vphi(\vec x)}
        &= \ddi{}{\dot\vphi(\vec x)}\int d^3y\, \mc
        L(\vphi(y),\dot\vphi(y))\\
        &\sim \ddi{}{\dot\vphi(\vec x)}\sum \mc
        L(\vphi(y),\dot\vphi(y)) d^3y\\
        &= \ddi{\mc L}{\dot\vphi(\vec x)} d^3x\\
        &\equiv \pi(\vec x)d^3 x
    \end{align*}
    since each point on the lattice represents a different variable, so the
    derivative just picks out the one at $\vec x$. We call $\pi(\vec x)$
    the momentum \emph{density}. Therefore the Hamiltonian looks like:
    \[H = \int d^3x\, \left[\pi(\vec x)\dot\vphi(\vec x) - \mc L\right].\]
    (See the stress-energy tensor part for another derivation of the
    Hamiltonian which falls out of Noether's theorem for being the
    conserved quantity under time translations.)
    
    One might ask why we are still singling out the time-parameter in
    the Hamiltonian formalism when we write $p(\vec{x}) = \partial \mc
    L/\partial \dot\vphi(\vec x)$ instead of making it seem more
    Lorentz invariant by considering $\partial \mc
    L/\partial(\partial_\mu \vphi(\vec x))$ instead. This is because
    although special relativity dictates that time transforms with
    space, we still cannot treat them equally as coordinates. The
    Hamiltonian is, by definition, the infinitesimal generator of time
    translations, and hence is intrinsically associated with only the
    time coordinate. In fact, it is not true that the Hamiltonian
    density is always Lorentz invariant.
    
\item \textbf{Important example:} Take $\mc L = \FR{1}{2}(\di_\mu\vphi)^2 -\FR{1}{2}
    m^2\vphi^2$. Euler-Lagrange equations become $\di^\mu(\di_\mu
    \vphi)+m^2\vphi=0$ which is the Klein Gordon equation. The Hamiltonian
    becomes:
    \[ H = \int d^3x \mc H
= \int d^3x \left[ \underbrace{\FR{\pi^2}{2}}_{\text{moving in time}}
    + \underbrace{\FR{(\nabla \vphi)^2}{2}}_{\text{shearing in space}}
+ \underbrace{\FR{m^2\vphi^2}{2}}_{\text{existing at all}}\right]\]
    \end{itemize}
    
\subsection{Noether's Theorem - How to Compute Conserved Quantities}
To every continuous transformation of the field we can assign an infinitesmal
transformation:
\[ \vphi(x) \rightarrow \vphi'(x) = \vphi(x) +
\alpha\underbrace{\Delta\vphi(x)}_{\text{deformation}}\]
Transformations might also change the Lagrangians. The interplay between
how the infinitesmal transformation changes the Lagrangian and the field is
what gives rise to conserved quantities, or sometimes known as Noether charges.
\begin{align*}
    \text{Symmetry} &\iff \text{Equations of motion -- invariant}\\
    &\iff \text{Action invariant (up to surface term)}\\
    &\iff \mc L(x) \rightarrow \mc L(x) + \alpha\di_mu \mc J^\mu(x)
\end{align*}
Taylor expanding the perturbation:
\begin{align*}
    \Delta \mc L &= \ddi{\mc L}{\vphi} \cdot \Delta \vphi + \ddi{\mc
    L}{(\di_\mu\vphi)}\di_\mu(\Delta\vphi)\\
    &= \di_\mu\left( \ddi{\mc L}{(\di_\mu\vphi)}\Delta\vphi \right) +
    \left[ \ddi{\mc L}{\vphi} - \di_\mu \left( \ddi{\mc L}{(\di_\mu \vphi)}
    \right) \right]\\
    &= \di_\mu\left( \ddi{\mc L}{(\di_\mu\vphi)}\Delta\vphi \right)\\
\end{align*}
Since we claimed that under the symmetry $\Delta\mc L = \di_\mu \mc J^\mu$
we have the following relations:
\begin{align*}
    j^\mu(x) &= \ddi{\mc L}{(\di_\mu\vphi)}\Delta\vphi - \mc J^\mu\\
    \di_\mu j^\mu &= 0\\
    \ddi{}{t} j^0 &= \di_i j^i
\end{align*}
Define the charge $Q = \int d^3x\; j^0$. Then, if we assume that space does
not have boundary, Stokes' theorem implies that $\di Q/\di t = 0$. Often,
$j^0$ is called the charge density, and $j^\mu$ is called the current
density.

%   \begin{mdframed}
%   Therefore to compute a conserved quantity we compare the deformation of the
%   Lagrangian due to the $\vphi$ changing with the deformation of the
%   Lagrangian due to the symmetry transformation. 
%   \end{mdframed}

\textbf{Examples:}
\begin{enumerate}
    \item $\mc L = \FR{1}{2}(\di_\mu \vphi)^2$ has the following field
        symmetry, $\vphi \to \vphi+\alpha$, ie. $\Delta\vphi \equiv$ const.
        There is no change to the Lagrangian, so $j^\mu = \di^\mu \vphi$.
    \item Space-time transformation, $x^\mu \to x^\mu-a^\mu$, implies
        \begin{align*}
        \vphi(x) &\to \vphi(x+a) = \vphi(x) + a^\nu\di_\nu\vphi(x)\\
        \mc L(x) &\to \mc L(x+a) = \mc L(x) + a^\mu\di_\mu \mc L\\
                 &. \quad\qquad\qquad = \mc L(x) +
                 a^\nu\di_\mu(\delta^\mu_\nu \mc L)
        \end{align*}
        Therefore we write 
        \[T^\mu_\nu = \ddi{\mc L}{(\di_\mu\vphi)}\di_\nu\vphi -
        \delta^\mu_\nu\mc L\]
        we get four separately conserved quantities.

        This is called the {\bf stress-energy tensor} or the {\bf
          energy-momentum tensor} in various contexts. The $T^{\bullet
          0}$ quantity gives rise to the Hamiltonian:
        \begin{align*}
            \int d^3x T^{00} = \int d^3x \mc H \equiv H
        \end{align*}

\end{enumerate}

%   \subsection{Summary of Computing Noether Charges}
%   Field or coordinate transformation $\leadsto$ $\{\Delta\phi,\Delta\mc L\}$
%   $\leadsto j^\mu(x) = \ddi{\mc L}{(\di_\mu\vphi)}\Delta\vphi - \mc J^\mu$
%   $\leadsto Q = \int j^0 d^3x$ conserved charge.

\section{Quantizing the Klein-Gordon Field}

Before we quantize, let's apply the classical theory to the classical
Klein-Gordon field, which is defined by the Lagrangian
$$ \cL = \frac{1}{2} \dot\phi^2 - \frac{1}{2} (\nabla \phi)^2 -
\frac{1}{2} m^2 \phi^2 = \frac{1}{2} (\partial_\mu \phi)^2 -
\frac{1}{2} m^2 \phi^2, $$ where $\phi(\vec{x})$ is the real-valued
     {\bf classical Klein-Gordon field}. We will interpret $m$ as a
     mass later on, but for now it is just a parameter.

\begin{exercise}
  By applying Euler-Lagrange, confirm that this Lagrangian for the
  classical Klein-Gordon field indeed gives the Klein-Gordon equation
  $(\partial^\mu \partial_\mu + m^2)\phi = 0$, and compute the
  Hamiltonian
  $$ H = \int d^3x \, \cH = \int d^3x \, \left(\frac{1}{2} \pi^2 +
  \frac{1}{2}(\nabla \phi)^2 + \frac{1}{2} m^2\phi^2\right). $$ (You
  should get that $\pi = \dot \phi$).
\end{exercise}

Now we enter the QFT world. For now we will work in the Schr\"odinger
picture, where $\phi(\vec x)$ and $\pi(\vec y)$ are time-independent.
We will take the classical Klein-Gordon field and {\bf canonically
  quantize} it, which involves two steps:
\begin{enumerate}
\item promote $\phi$ and $\pi$ to operators (i.e. $\phi(\vec{x})$ and
  $\phi(\vec{y})$ are now operators, not scalars), and
\item specify the commutation relations
  \begin{align*}
    [\phi(\vec x),\pi(\vec y)] &= i\delta^{(3)}(\vec x-\vec y)\\
    [\phi(\vec x),\phi(\vec y)] &= [\pi(\vec x),\pi(\vec y)] = 0.
  \end{align*}
  This is in analogy with the QM of a multiparticle system, where if
  $q_i$ and $p_i$ are the momentum and position operators of the
  $i$-th particle, then
  \begin{align*}
    [q_i, p_j] &= i\delta_{ij}\\
    [q_i, q_j] &= [p_i, p_j] = 0,
  \end{align*}
  except now we have a continuum of particles, indexed by the
  continuous variable $\vec{x}$ instead of a discrete variable $i$.
\end{enumerate}
Note that these commutation relations are taken to be {\bf axioms}. At
this point one may wonder why we treat $\phi$ and $\pi$ as different
operators when $\pi = \dot\phi$ for Klein-Gordon. This is for the same
reason that $x$ and $\dot x$ are treated independently in classical
field theory: we abuse notation and write $(x, \dot x)$ as coordinates
on phase space, when really we should be writing $(x, p)$. But we
write $\dot x$ because we will always be evaluating objects on phase
space at $(x, \dot x)$.

But of course, imposing these axioms is easier said than done. What do
$\phi$ and $\pi$ look like?

Let us try to motivate the form of the expression for $\phi$ and its
conjugate $\pi$ in terms of creation and annihilation operators.
\footnote{Quibble: I don't like how it is done in Peskin. Why promote the
coefficients in the Fourier transform, and why do \emph{they} give rise to
the creation and annihilation operators. I think there might be a good
explanation out there already; Landau\& Lifshitz, and Weinberg (Chapter 5) seem to take
a good wack at the physics of this choice. Actually, in LL, the exposition
seems to have avoided some of the integral manipulations that happened in
Peskin and Schroeder.}

If we expand a solution to the Klein Gordon equation in a Fourier basis of
plane waves, then we see that we naturally have some variables that we can
quantize. What's more interesting is that the Klein Gordon equation gives
rise to precisely the harmonic oscillator example from first year quantum
mechanics. In terms of creation and annihilation operators, the first years
wrote $\hat q = \FR{1}{\sqrt{2\om}}(a+a^\dag)$, $\hat p =
\SFR{\om}{2}(a-a^\dag)$. Therefore we conjecture our fields have the
following form: \footnote{{\elaborate}}
\newcommand{\vp}{{\vec p}}
\newcommand{\vx}{{\vec x}}
\begin{align*}
\phi(\vx) &= \int \FR{d^3p}{(2\pi)^3} \FR{1}{\sqrt{2\om_p}} (a_\vp e^{i\vp\cdot\vx} + a_\vp^\dag e^{-i\vp\cdot\vx})\\
\pi(\vx) &= \int \FR{d^3p}{(2\pi)^3}(-i)\SFR{\om_p}{\sqrt2} (a_\vp e^{i\vp\cdot\vx} - a_\vp^\dag e^{-i\vp\cdot\vx})
\end{align*}

\chapter{Dirac Field}
The formalism that we have built up so far tells that everything starts
from a Lagrangian. In the theory of elementary particles and high energy
physics there is one very special condition that we require of a
Lagrangian: Lorentz invariance. To check whether a given expression of
$\phi$'s and $\di_\mu\phi$'s is Lorentz invariant we must understand how
arbitrary field transform under the Lorentz group. Suppose a field has
components $\phi_a$, then a general transformation is given by
\[ \phi_a'(x) = M(\Lambda)_{ab}\phi_b(\Lambda^{-1}x). \]
Thus, to solve the problem of constructing all Lagrangians we must first
understand the representations of the Lorentz group, or at least of the
Lorentz algebra. Taking a cue from the $\so(3)$ generators given by
$J^{ij}=-i(x^i\di^j-x^j\di^i)$ it turns out that the generators for the
Lorentz algebra are:
\[ J^{\mu\nu} = i(x^\mu\di^\nu-x^\nu\di^\mu).\]
This gives commutation relations
\[ [J^{\mu\nu},J^{\rho\sg}] = \dots .\]
The defining representation is given by the following$(\mc
J^{\mu\nu})_{ab} = -i\delta^\mu_{[a}\delta^\nu_{b]}
=-i(\delta^\mu_{a}\delta^\nu_{b} -\delta^\mu_{b}\delta^\nu_{a})$
Dirac came up with another representation by taking 4 $n\times n$ matrices
$\gam^\mu$ satisfying ${\gam^\mu,\gam^\nu} = 2g^{\mu\nu}\times
\iden_{n\times n}$ and defining:
\[ S^{\mu\nu} = \FR{i}{4}[\gam^\mu,\gam^\nu].\]
If we define $\sg = (\iden,\vec\sigma)$ and $\bar\sg = (\iden,-\vec\sg)$
then \[\gam^\mu = \begin{pmatrix}0&\sg^\mu\\\bar\sg^\mu&0 \end{pmatrix}\] satisfies
the commutation relations and gives rise to the \textbf{Dirac
representation}. Objects that transform under that transform under this
representation are called $4$-component Dirac spinors, or just \textbf{Dirac
spinors} for short. 

Taking $\bar\psi = \gam^0\psi^\dag$, the Dirac equation, Lagrangian are
given by:
\begin{align*}
    (i\gam^\mu\di_\mu - m)\psi &= 0\\
    \mc L_{\text{Dirac}} &= \bar\psi(i\gam^\mu\di_\mu-m)\psi
\end{align*}
The conjugate variable to $\psi$ is $i\psi^\dag$. Before quantizing we
solve the Dirac equation in plane waves, $u(p)e^{i\vec p\cdot
\vec x}$ and $v(p)e^{-i\vec p\cdot \vec x}$. After rewriting the Dirac
equation into a matrix equation it is not hard to see that arbitrary
solutions $u(p)$ and $v(p)$ are given by the following expressions:
\begin{align*}
    u^s(p) &= \sqrt{m}\begin{pmatrix} \sqrt{p\cdot \sg} \xi^s\\
                      \sqrt{p\cdot \sg} \xi^s\end{pmatrix}\\
    v^s(p) &= \sqrt{m}\begin{pmatrix} \sqrt{p\cdot \sg} \eta^s\\
                      -\sqrt{p\cdot \sg} \eta^s\end{pmatrix}
\end{align*}
where, for $s=1,2$, $\{\xi^s\}$ and $\{\eta^s\}$ are a basis for $\bC^2$
and $\sqrt{p\cdot \sg}$ is the square root of the positive eigenvalue of
the associated matrix. (Phew, what a mouthful!)


Finally, we quantize this theory by introducing the \textbf{anticommutation
relations} and rewriting $\psi$ and $\bar\psi$ using raising and lowering
operators
\begin{align*} 
\{\psi(x),\bar\psi(y)\} &= \delta^{(3)}(\vec x-\vec y)\\
\psi(x) &= \int \FR{d^3p}{(2\pi)^3} 
\ha^{s\dag}_\vp u^s(\vp) e^{-i\vp\cdot\vx} -
\hb^{s\dag}_\vp v^s(\vp) e^{i\vp\cdot\vx} \\
\bar\psi(x) &= \int \FR{d^3p}{(2\pi)^3} 
\hb^{s\dag}_\vp \bar v^s(\vp) e^{-i\vp\cdot\vx} -
\ha^{s\dag}_\vp \bar u^s(\vp) e^{i\vp\cdot\vx}
\end{align*}
Using these cleverly chosen expressions we may write the Hamiltonian as
\begin{align*}
    H &= \int \FR{d^3p}{(2\pi)^3}  \sum_s
    E_\vp(\ha^{s\dag}_\vp\ha^{s}_\vp+ \hb^{s\dag}_\vp\hb^{s\dag}_\vp)\\
    Q &= \int \FR{d^3p}{(2\pi)^3}  \sum_s
    (\ha^{s\dag}_\vp\ha^{s\dag}_\vp - \hb^{s\dag}_\vp\hb^{s}_\vp)
\end{align*}
where $Q$ is the conserved quantity coming from gauge invariance,
$\psi'(x)=e^{\alpha(x)}\psi(x)$, of $\mc L_{\text{Dirac}}$.

\chapter{Path Integrals}

So far, we have taken classical field theories and canonically
quantized them to obtain the corresponding QFTs. In general, this
canonical quantization process is difficult and tedious, but it
motivates much of what we are about to do. The path integral approach
to QFT will allow us to perform calculations more easily, and
generalizes readily to other non-interacting theories. In particular,
for the entirety of this chapter, we will mostly be concerned with
calculating {\bf propagation amplitudes}.

\section{Deriving the Path Integral}

Suppose we have the Hamiltonian $\hat{H}$ for a quantum mechanical
particle, and we want to compute the amplitude
$\braket{\vec{q}_b|e^{-i\hat{H}t}|\vec{q}_a}$, i.e. the amplitude for
the particle to travel from the point $\vec{q}_a$ to $\vec{q}_b$ in a
given time $t$. Using the superposition principle, let's compute this
by splitting up the time interval $[0, t]$ into $n$ equal chunks of
size $\delta t = t/n$:
$$ \braket{\vec{q}_b|e^{-i\hat{H}t}|\vec{q}_a} = \int \cdots \int d\vec{q}_1 \cdots d\vec{q}_{n-1} \braket{\vec{q}_b|e^{-i\hat{H}\delta t}|\vec{q}_{n-1}} \braket{\vec{q}_{n-1}|e^{-i\hat{H}\delta t}|\vec{q}_{n-2}} \cdots \braket{\vec{q}_1|e^{-i\hat{H}\delta t}|\vec{q}_a}. $$
What have we done? We are saying that the amplitude for propagation
from $\vec{q}_a$ to $\vec{q}_b$ is equal to the amplitude for
propagation from $\vec{q}_a$ to $\vec{q}_1$, then to $\vec{q}_2$, and
so on, until $\vec{q}_b$, integrated over all possible $\vec{q}_j$.
(Recall the double slit experiment and consider the case $n = 2$ if
you are still confused.)

Now each of the terms needs to be evaluated. For convenience, let
$\vec{q}_n$ denote $\vec{q}_b$. Let's do the simple case where
$\hat{H} = \hat{p}^2/2m$, a free particle. A straightforward
calculation shows:
\begin{align*}
  \braket{\vec{q}_{j+1}|e^{-i(\hat{p}^2/2m)\delta t}|\vec{q}_j}
  &= \int \frac{d^3p}{(2\pi)^3} \, \braket{\vec{q}_{j+1}|e^{-i(\hat{p}^2/2m)\delta t}|p}\braket{p|\vec{q}_j} \\
  &= \int \frac{d^3p}{(2\pi)^3} \, e^{-i(p^2/2m)\delta t} \braket{\vec{q}_{j+1}|p}\braket{p|\vec{q}_j} \\
  &= \int \frac{d^3p}{(2\pi)^3} \, e^{-i(p^2/2m)\delta t} e^{ip(\vec{q}_{j+1} - \vec{q}_j)}.
\end{align*}
Ah, we know how to evaluate this integral: it's just a Gaussian! The
final result, after some suggestive rearranging, is
$$ \braket{\vec{q}_{j+1}|e^{-i(\hat{p}^2/2m)\delta t}|\vec{q}_j} = \left(\frac{m}{2\pi i\delta t}\right)^{3/2} \exp\left(i\delta t \frac{m}{2}\left(\frac{\vec{q}_{j+1} - \vec{q}_j}{\delta t}\right)^2\right). $$
(The Gaussian integral itself is not trivial. \footnote{The relevant
formula is as follows. For $A \in \GL(n, \bC)$ such that $A = A^T$
and $\re A$ is positive semidefinite,
$$ \int d^nx \, e^{-Ax \cdot x/2 + iy \cdot x} = \frac{(2\pi)^{n/2}}{\sqrt{\det A}} e^{-A^{-1} y^2/2}. $$ 
One proves this by showing it first for $n = 1$ and $A = I$, in which
case it suffices to solve the DE
$$ \frac{d}{dy} \int dx \, e^{-x^2/2 + iyx} = -y \int dx \, e^{-x^2/2 + iyx}. $$
Now suppose $A$ is real and hence PSD. If we plug $x = \sqrt{A}v$ into
the LHS of the formula, the RHS splits as a product of one-dimensional
integrals, which we just calculated. Finally, since both sides are
analytic and agree for real PSD matrices, they agree in general.})
Hence when we plug this back into our calculation for
$\braket{\vec{q}_b|e^{-i\hat{H}t}|\vec{q}_a}$, we get
$$ \braket{\vec{q}_b|e^{-i\hat{H}t}|\vec{q}_a} = \left(\frac{m}{2\pi i\delta t}\right)^{3n/2} \int d\vec{q}_1 \cdots d\vec{q}_{n-1} \exp\left(i\delta t \frac{m}{2}\sum_{j=1}^{n-1} \left(\frac{\vec{q}_{j+1} - \vec{q}_j}{\delta t}\right)^2\right). $$
So far, everything we have done is rigorous. But now we make an
intuitive leap: instead of approximating the propagation from
$\vec{q}_a$ to $\vec{q}_b$ with a finite number of timesteps, we use
infinitely many. In other words, we ``integrate over paths'' by
letting $\delta t \to 0$ and $n \to \infty$, giving the formal
expression
$$ \braket{\vec{q}_b|e^{-i\hat{H}t}|\vec{q}_a} = \int D\vec{q}(t) \, \exp\left(i \int_0^t dt \, \frac{1}{2} m \vec{q}'(t)^2\right) $$
where the {\bf path integral} $\int D\vec{q}(t)$ is defined as
$$ \int D\vec{q}(t) = \lim_{n \to \infty} \left(\frac{m}{2\pi i\delta t}\right)^{3n/2} \int \cdots \int d\vec{q}_1 \cdots d\vec{q}_{n-1}. $$

\begin{exercise}
  Perform the same derivation of the path integral, but now starting with the Hamiltonian $\hat{H} = \hat{p}^2/2m + V(\hat{q})$. You should get
  $$ \braket{\vec{q}_b|e^{-i\hat{H}t}|\vec{q}_a} = \int D\vec{q}(t) \, \exp\left(i \int_0^t dt \, \frac{1}{2} m \vec{q}'(t)^2 - V(\vec{q}(t))\right). $$
\end{exercise}

For now, let's not worry about the infinite constant in front of the
path integral; it pales as an issue in comparison to the nonexistence
of a Lebesgue measure on the space of paths. Actually, the constant
will cancel out later.

Note that the integrand looks suspiciously like the Lagrangian
corresponding to the Hamiltonian in both cases. This is indeed true,
and can be demonstrated by plugging in a general Hamiltonian
$\hat{H}(\hat{q}, \hat{p})$ and seeing how combinations of $\hat{q}$
and $\hat{p}$ act on the $\ket{\vec{q}_i}$.

\begin{theorem}
  Suppose $\hat{H}(\vec{q}, \vec{p})$ is a {\bf Weyl-ordered}
  Hamiltonian, i.e. in a form where if there is a term
  $\vec{p}^{i_1} \vec{q}^{i_2} \cdots \vec{p}^{i_n}$, then there is a
  corresponding term
  $\vec{p}^{i_n} \vec{q}^{i_{n-1}} \cdots \vec{p}^{i_1}$. Then
  $$ \braket{\vec{q}_b|e^{-i\hat{H}t}|\vec{q}_a} = \int D\vec{q}(t) D\vec{p}(t) \, \exp\left(i \int_0^t dt \, \vec{p}(t) \cdot \vec{q}(t) - H(\vec{q}(t), \vec{p}(t))\right). $$
  In particular, for Hamiltonians quadratic in $\vec{p}$, we can
  integrate away the $\int D\vec{p}(t)$, leaving only the Lagrangian
  in the integrand.
\end{theorem}

\begin{proof}
  Details of the long calculation will not bring us much further
  enlightenment, so we omit them. See Peskin \& Schroeder, pages
  280-281 iff you like calculations and have some time to burn.
\end{proof}

Any Hamiltonian can be Weyl-ordered by commuting $\hat{p}$ and
$\hat{q}$, so this theorem is very general. In fact, it is general
enough that from now on, we will work directly with the Lagrangian and
almost completely ignore the Hamiltonian formalism. There is one major
advantage in doing so: the Lagrangian makes symmetries and
conservation laws very clear. For example, when we write down a
Lorentz-invariant Lagrangian, the path integral is automatically
Lorentz-invariant.

In fact, the quantum system we are considering is very general as
well. In our entire derivation of the path integral, we did not use
anything beyond the relationship between $\hat{q}$ and $\hat{p}$. So
in particular, our derivation holds not only for quantum mechanical
systems, but also for QFTs. For example, if we take the Lagrangian
$\cL = \frac{1}{2} (\partial_\mu \phi)^2 - V(\phi)$ for a real scalar
field, then
$$ \braket{\phi_b(\vec{x}) | e^{-iHt} | \phi_a(\vec{x})} = \int D\phi \exp\left(i \int_0^t d^4x \, \frac{1}{2} (\partial_\mu \phi)^2 - V(\phi)\right). $$

\section{The Generating Functional}

If we take
$\cL = \frac{1}{2} (\partial_\mu \phi)^2 - \frac{1}{2} m^2\phi^2$, we
get a the path integral corresponding to the Klein-Gordon field, which
we are already familiar with. So let's add a general perturbation
term:
$$ \cL = \frac{1}{2} (\partial_\mu\phi)^2 - \frac{1}{2} m^2\phi^2 + J\phi, $$
where here $J(x)$ is a function of $x$, representing an {\bf
  excitation}, and usually called a {\bf source function}. The
resulting path integral is written
$$ Z[J] = \int D\phi \exp\left(i \int_0^t d^4x \, \frac{1}{2} (\partial_\mu \phi)^2 - \frac{1}{2}m^2\phi^2 + J\phi\right). $$

{\bf Note}: adding a source function is not the same thing as adding
an interaction. Source functions merely allow us to create sources and
sinks, whereas interactions allow the excitations generated by the
sources and sinks to interact with themselves. Here we are still
working within a free Klein-Gordon theory.

We can write $Z[J]$ in a very explicit form. First, let's rewrite the
Lagrangian a little via integration by parts:
$$ \int_0^t d^4x \, \frac{1}{2} (\partial_\mu \phi)^2 - \frac{1}{2} m^2\phi^2 + J\phi = \int_0^t d^4x \, \frac{1}{2} \phi(-\partial^2 - m^2)\phi + J\phi. $$
We will evaluate this a little informally, but the entire argument can
be made formal once we introduce the Green's function (the definition
of which will be motivated by this argument). Imagine that the
integral above is actually a giant sum,
$\phi = (\phi_1, \ldots, \phi_n)$ is merely a vector, and
$(-\partial^2 - m^2) = A$ merely an $n \times n$ matrix. Then $Z[J]$
becomes
$$ \int d\phi_1 \cdots \int d\phi_n \, \exp\left(\frac{i}{2} \phi^T A \phi + iJ\phi\right) = \left(\frac{(2\pi i)^n}{\det A}\right)^{\frac{1}{2}} \exp\left(-\frac{i}{2} JA^{-1}J\right). $$
Physicists call this process ``discretizing spacetime,'' which sounds
cooler.

Now we want to pass back into the continuum limit, i.e. replace $\phi$
as a vector with $\phi$ as a field, and $A$ with
$(-\partial^2 - m^2)$. But what should be replace $A^{-1}$ by? In the
discretized case, we had $AA^{-1} = I$, so by analogy, we should
replace $A^{-1}$ by a function $G(x - y)$ satisfying
$$ (-\partial^2 - m^2)G(x - y) = \delta(x - y). $$
Such a function $G(x - y)$ is a {\bf Green's function} for the linear
differential operator $(-\partial^2 - m^2)$. So we pause quickly to
introduce Green's functions and related objects.

\subsection{Green's Functions and Propagators}

\begin{definition}
  Given a linear differential operator $L(x)$ (acting on distributions), its {\bf Green's function} $G(x - y)$ satisfies $L(x)G(x - y) = -i\delta(x - y)$. Hence given a differential equation of the form $L(x)u(x) = f(x)$, we can compute
  $$ L(x) \int dy \, G(x - y)f(y) = \int L(x) G(x - y) f(y) \, dy = -i \int \delta(x - y) f(y) \, dy = -i f(x), $$
  so that $u(x) = i \int dy \, G(x - y) f(y)$ is a solution.
\end{definition}

For example, the defining property of the Green's function $G(x - y)$ for the Klein-Gordon operator $(\partial^2 + m^2)$ can be written in momentum space:
$$ (\partial^2 + m^2) \int \frac{d^4p}{(2\pi)^4} e^{-ip(x-y)} \tilde{G}(p) = \int \frac{d^4p}{(2\pi)^4} e^{-ip(x-y)}. $$
Then it is easy to solve for $\tilde{G}(p)$. Equating the two integrands,
$$ (\partial^2 + m^2) e^{-ip(x-y)} \tilde{G}(p) = (-p^2 + m^2) e^{-ip(x-y)} \tilde{G}(p) = -i e^{-ip(x-y)}, $$
so we can directly write
$$ G(x - y) = \int \frac{d^4p}{(2\pi)^4} e^{-ip(x-y)} \tilde{G}(p) = \int \frac{d^4p}{(2\pi)^4} e^{-ip(x-y)} \frac{i}{p^2 - m^2}. $$

Here we must pause for a moment: there is something wrong with this integral. When we integrate over $p$, there are two singularities at $p^0 = \pm E_{\vec p}$, so this integral diverges. That's okay, say the physicists, let's just specify how we treat the poles, and write down the following version of the Green's function:
$$ D_F(x - y) = \int \frac{d^4p}{(2\pi)^4} e^{-ip(x-y)} \tilde{G}(p) = \int \frac{d^4p}{(2\pi)^4} e^{-ip(x-y)} \frac{i}{p^2 - m^2 + i\epsilon}. $$
Now the poles are displaced above and below the real $p^0$ axis, at $p^0 = \pm (E_{\vec p} - i\epsilon)$ in the ``complex $p^0$ plane'', and we don't have divergence issues anymore. This version of the Green's function is called the {\bf Feynman propagator}. 

\begin{exercise}
  Let $\theta(x - y)$ be the {\bf Heaviside step function}, i.e. it is $1$ when $x > y$, and $0$ otherwise. Compute that
  $$ D_F(x - y) = \theta(x^0 - y^0) \int \frac{d^3\vec{p}}{(2\pi)^3} \frac{1}{2E_{\vec p}} e^{-ip(x-y)}\bigg|_{p^0 = E_{\vec p}} + \theta(y^0 - x^0) \int \frac{d^3\vec{p}}{(2\pi)^3} \frac{1}{2E_{\vec p}} e^{-ip(x-y)}\bigg|_{p^0 = E_{-\vec p}} $$
  by analytic continuation into the complex $p^0$ plane, and by closing the contour either in the upper half plane when $x^0 > y^0$, or in the lower half plane when $x^0 < y^0$:
\end{exercise}

Why is the Green's function $D_F(x - y)$ called a propagator? The answer lies in computing the amplitude $\braket{0|\phi(\vec x)\phi(\vec y)|0}$ for a particle to propagate from a point $\vec{x}$ in space to another point $\vec{y}$ in space:
\begin{align*}
  \braket{0|\phi(x)\phi(y)|0} 
  &= \int \frac{d^3\vec{p}_1}{(2\pi)^3 \sqrt{2E_{\vec{p}_1}}} \int \frac{d^3\vec{p}_2}{(2\pi)^3 \sqrt{2E_{\vec{p}}}} e^{-i\vec{p}_1\vec{x}} e^{i\vec{p}_2\vec{y}} \braket{0|[a_{\vec{p}_1}, a^\dagger_{\vec{p}_2}]|0} \\
  &= \int \frac{d^3\vec{p}}{(2\pi)^3 (2E_{\vec p})} e^{-i\vec{p}(\vec{x} - \vec{y})}\bigg|_{p^0 = E_{\vec p}}.
\end{align*}
Hence we have
$$ D_F(x - y) = \theta(x^0 - y^0)\braket{0|\phi(\vec x)\phi(\vec y)|0} + \theta(y^0 - x^0)\braket{0|\phi(\vec y)\phi(\vec x)|0}. $$
The physical interpretation is that the Green's function $D_F(x - y)$ is the amplitude for a particle to propagate from $x$ to $y$ or $y$ to $x$, depending on which of $x$ and $y$ came first in time. This interpretation will allow us to prescribe some physical meaning to the Feynman diagrams we are about to draw.

\subsection{Computing and Using the Generating Functional}

Now that we know about Green's functions, let's return to computing the generating functional $Z[J]$. Recall that we left off at passing back into the continuum limit from the discretized path integral
$$ \int d\phi_1 \cdots \int d\phi_n \, \exp\left(\frac{i}{2} \phi^T A \phi + iJ\phi\right) = \left(\frac{(2\pi i)^n}{\det A}\right)^{\frac{1}{2}} \exp\left(-\frac{i}{2} JA^{-1}J\right). $$
Now we know what to replace $A^{-1}$ with: the Green's function $-iD_F(x - y)$. Hence
$$ Z[J] = C \exp\left(-\frac{1}{2} \int d^4x \, d^4y \, J(x) D_F(x - y) J(y)\right) $$
for some constant $C$. What is $C$? We don't care about its exact value, but clearly it is $Z[0]$. We have proved the following result.

\begin{proposition}
  Let
  $$ D_F(x - y) = \int \frac{d^4p}{(2\pi)^4} \frac{e^{ik(x-y)}}{k^2 - m^2 + i\epsilon}. $$
  Then
  $$ Z[J] = Z[0] \exp\left(-\frac{1}{2} \int d^4x \, d^4y \, J(x) D_F(x - y) J(y)\right). $$
\end{proposition}

A few comments are appropriate at this point.
\begin{enumerate}
\item Remember how earlier we claimed that the infinite constant in the path integral would cancel? We will be looking at the quantity $Z[J]/Z[0]$, so indeed, the constant disappears!
\item One may wonder why $Z[J]$ is called the generating functional. What is it a generating function of?
\end{enumerate}


\end{document}
