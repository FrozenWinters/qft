\documentclass{report}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amscd}
\usepackage{fullpage}
\usepackage{braket}
\usepackage{dsfont}
\usepackage{mdframed}
\usepackage{tikz}
\usetikzlibrary{positioning}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{axiom}{Axiom}
\newtheorem{example}[theorem]{Example}
\newtheorem{exercise}{Exercise}[section]

\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{note}{Note}

\newcommand{\FR}[2]{\frac{#1}{#2}}
\newcommand{\PFR}[2]{\left(\frac{#1}{#2}\right)}
\newcommand{\SFR}[2]{\sqrt{\frac{#1}{#2}}}

\newcommand{\mc}{\mathcal}
\newcommand{\lam}{\lambda}
\newcommand{\vphi}{\varphi}
\newcommand{\om}{\omega}
\newcommand{\Om}{\Omega}
\newcommand{\gam}{\gamma}
\newcommand{\sg}{\sigma}
\newcommand{\di}{\partial}
\newcommand{\ddi}[2]{\FR{\partial {#1}}{\partial {#2}}}
\newcommand{\hp}{\hat p}
\newcommand{\ha} { a}
\newcommand{\hb} { b}
\newcommand{\hbd} { b^\dagger}
\newcommand{\had}{ a^\dagger}
\newcommand{\iden}{\mathds{1}}

\newcommand{\elaborate}{{\color{blue} \textbf{Elaborate.}}}
\newcommand{\CHECK}{{\color{blue} \textbf{CHECK}}}

\DeclareMathOperator{\bC}{\mathbb{C}}
\DeclareMathOperator{\bR}{\mathbb{R}}
\DeclareMathOperator{\bP}{\mathbb{P}}
\DeclareMathOperator{\bN}{\mathbb{N}}
\DeclareMathOperator{\bZ}{\mathbb{Z}}
\DeclareMathOperator{\cA}{\mathcal{A}}
\DeclareMathOperator{\cB}{\mathcal{B}}
\DeclareMathOperator{\cC}{\mathcal{C}}
\DeclareMathOperator{\cD}{\mathcal{D}}
\DeclareMathOperator{\cF}{\mathcal{F}}
\DeclareMathOperator{\cH}{\mathcal{H}}
\DeclareMathOperator{\cI}{\mathcal{I}}
\DeclareMathOperator{\cJ}{\mathcal{J}}
\DeclareMathOperator{\cL}{\mathcal{L}}
\DeclareMathOperator{\fg}{\mathfrak{g}}
\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\im}{Im}
\DeclareMathOperator{\re}{Re}
\DeclareMathOperator{\Ad}{Ad}
\DeclareMathOperator{\Sp}{Sp}
\DeclareMathOperator{\SO}{SO}
\DeclareMathOperator{\GL}{GL}
\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\Aut}{Aut}
\DeclareMathOperator{\so}{so}

\begingroup
    \makeatletter
    \@for\theoremstyle:=definition,remark,plain\do{%
        \expandafter\g@addto@macro\csname th@\theoremstyle\endcsname{%
            \addtolength\thm@preskip\parskip
            }%
        }
\endgroup

\edef\restoreparindent{\parindent=\the\parindent\relax}
\usepackage{parskip}
\restoreparindent

\tikzset{
  particle/.style={thick,draw=black},
  gluon/.style={decorate,draw=black,decoration={coil,aspect=0}},
  vertex/.style={shape=circle,scale=0.3,fill=black,draw=black},
  every loop/.style={thick,draw=black}
}

\setcounter{chapter}{-1}

\title{Quantum Field Theory\\Fall 2015 Seminar Notes}
\author{Anton Borissov, Henry Liu}
\date{\today}

\begin{document}

\maketitle

\tableofcontents

\chapter{Review}

Let's review some notation and concepts from quantum mechanics and
special relativity. Note that not all these concepts carry over to
quantum field theory. For example, in quantum mechanics, we are always
working with states within some Hilbert space, but in quantum field
theory, there is no suitable Hilbert space.

\section{Quantum Mechanics}

The fundamentals of quantum mechanics have had almost a century to be
formalized, and indeed they have been! Here we give a somewhat
axiomatic presentation of QM.

\begin{axiom}[States]
  Let $\cH$ be a (complex) Hilbert space. Its projectivization
  $\bP\cH$ is the {\bf state space} of our system.
  \begin{itemize}
  \item An element of $\cH$, i.e. a state, is called a {\bf ket}, and
    is written $\ket{x}$.
  \item An element of $\cH^*$, i.e. a functional, is called a {\bf
      bra}. The bra associated to $\ket{x}$ (under the identification
    $\cH \cong \cH^*$ given by the inner product) is denoted $\bra{x}$.
  \end{itemize}
  Consequently, $\braket{x|x} = \|x\|^2$, which we usually want to
  normalize to be $1$.

  Note that the symbol inside the ket or bra is somewhat arbitrary.
  For example, the states of a quantum harmonic oscillator are written
  $\ket{n}$, for $n \in \bN$.
\end{axiom}

Given a space of states, we can look at the operators that act on the
states. These operators must be unitary, so that normalized states go
to normalized states. 

\begin{axiom}[Observables]
  To every classical observable (i.e. property of a system) is
  associated a quantum operator, called an {\bf observable}.
  Observables are (linear) self-adjoint operators whose (real!)
  eigenvalues are possible values of the corresponding classical
  property of the system. For example,
  \begin{itemize}
  \item $\hat{H}$ is the {\bf Hamiltonian} of the system, which
    classically represents the ``total energy'' (kinetic + potential)
    in the system,
  \item $\hat{x}$ is the {\bf position operator},
  \item $\hat{p}$ is the {\bf momentum operator}.
  \end{itemize}
  The convention in QM is that observables are denoted by symbols with
  hats on them. The process of ``moving'' from a classical picture of
  a system to a quantum picture by making classical observables into
  operators is called {\bf quantization}, because the possible values
  of the observables are often quantized, i.e. made discrete, whereas
  previously they formed a continuum.
\end{axiom}

A classical observable is simple: it is just a function $f$ defined on
the classical phase space, so in order to make a measurement of the
observable, we simply apply $f$ to the current state of the system.
In QM it is not as simple, in most part due to its inherently
probabilistic nature. But it is still straightforward.

\begin{axiom}[Measurement]
  If $\hat{A}$ is the observable and $\hat{A}\ket{k} = a_k\ket{k}$,
  i.e. $\ket{k}$ is an eigenstate with eigenvalue $a_k \in \bR$, then
  the probability of obtaining $a_k$ as the value of the measurement
  on $\ket{\psi}$ is $|\braket{k|\psi}|^2$. But not only is the
  outcome probabilistic, the state of the system after the measurement
  is $\ket{k}$. In other words, {\bf measurement is projection}. This
  is fundamental to QM and cannot be emphasized enough.

  There are some conventions for position and momentum eigenstates.
  Since $\hat{x}$ and $\hat{p}$ are conventional symbols to use for
  position and momentum respectively, the states $\ket{x}$ and
  $\ket{p}$ are position and momentum eigenstates with eigenvalues $x$
  and $p$ respectively.
\end{axiom}

What about states that we don't measure? What are they doing as time
passes? We need to specify the {\bf dynamics} of our system, and this
is where the quantum analog of the Hamiltonian comes into play.

\begin{axiom}[Dynamics]
  The time-evolution of the state $\ket{\psi}$ is specified by the
  Hamiltonian $\hat{H}$ of the system, and is given by the {\bf
    Schr\"odinger equation}
  $$ i\hbar \frac{d\ket{\psi}}{dt} = \hat{H}\ket{\psi}, $$
  where $\hbar$ is Planck's constant (later we will be working in
  units where $\hbar = 1$). Note that we can solve this first-order ODE:
  $$ \ket{\psi(t)} = \exp(-i\hat{H}t)\ket{\psi(0)}. $$
  The operator $U(t) = \exp(-i\hat{H}t)$ is known as the {\bf
    time-evolution operator}.
\end{axiom}

That's it! There are some quick consequences of these axioms we should
explore before moving on. First, although measurement is
probabilistic, we often work with states whose observables tend to
take on values clumped around a certain value, which corresponds to
the classical value of that observable for the system. So given a
state $\ket{\psi}$ and observable $\hat{A}$, it is reasonable to
define the {\bf expectation value} and {\bf standard deviation}
$$ \braket{\hat{A}} = \braket{\psi|\hat{A}|\psi}, \qquad \Delta \hat{A} = \sqrt{\braket{\hat{A}^2} - \braket{\hat{A}}^2}. $$

\begin{proposition}[Heisenberg's uncertainty principle]
  Let $\hat{A}$ and $\hat{B}$ be self-adjoint operators. Then
  $$ \Delta \hat{A} \Delta \hat{B} \ge \frac{1}{2}\left|\braket{[\hat{A}, \hat{B}]}\right|. $$
\end{proposition}

\begin{proof}
  Note that the variance can also be written 
  $$ \Delta \hat{A} = \braket{\psi|(\hat{A} - \braket{A})^2|\psi}. $$
  Without loss of generality, assume
  $\braket{\hat{A}} = \braket{\hat{B}} = 0$, since we can shift
  $\hat{A}$ and $\hat{B}$ by constants without affecting
  $\Delta \hat{A}$ and $\Delta \hat{B}$. Then an application of
  Cauchy-Schwarz (using braket notation) gives
  $$ \Delta \hat{A} \Delta \hat{B} = \|\hat{A}\ket{\psi}\| \|\hat{B}\ket{\psi}\| \ge \left|\braket{\psi|\hat{A}\hat{B}|\psi}\right|. $$
  Now note that if $z = \braket{\psi|\hat{A}\hat{B}|\psi}$, then
  $|z| \ge |\im z| = |z - z^*|/2$. Hence
  $$ \left|\braket{\psi|\hat{A}\hat{B}|\psi}\right| \ge \frac{1}{2}\left|\braket{\psi|\hat{A}\hat{B}|\psi} - \braket{\psi|\hat{A}\hat{B}|\psi}^*\right| = \frac{1}{2}\left|\braket{\psi|\hat{A}\hat{B} - (\hat{A}\hat{B})^\dagger|\psi}\right| = \frac{1}{2}\left|\braket{\psi|[\hat{A}, \hat{B}]|\psi}\right|, $$
  where the last equality follows from the observables being
  self-adjoint:
  $(\hat{A}\hat{B})^\dagger = \hat{B}^\dagger\hat{A}^\dagger =
  \hat{B}\hat{A}$.
\end{proof}

For example, if we have a particle in $\bR^n$, the Hilbert space
underlying the state space is $\cH = L^2(\bR^n)$, and the position and
momentum operators are given by
$$ \hat{x}: \psi(x) \mapsto x\psi(x), \quad \hat{p}: \psi(x) \mapsto -i\hbar\nabla\psi(x). $$
A short calculation gives the {\bf fundamental commutation relation}
between $\hat{x}$ and $\hat{p}$:
$$ [\hat{x}, \hat{p}] = i\hbar, $$
which we interpret as saying that we cannot know both the exact
position and exact momentum of a particle at the same time.

\section{Special Relativity}

\setcounter{axiom}{0}

Special relativity describes the structure of spacetime. It says that
spacetime is $\bR^{1+3}$, known as {\bf Minkowski space} (as opposed
to $\bR^4$, Euclidean space) and equipped with the {\bf Minkowski
  metric}
$$ ds^2 = c^2 dt^2 - dx^2 - dy^2 - dz^2 $$
where $c$ is the speed of light (later we will work in units where
$c = 1$). As with QM, there is a nice axiomatic presentation of SR,
which is essentially just the following axiom.

\begin{axiom}[Lorentz invariance]
  The fundamental laws of physics must be invariant under isometries
  of Minkowski space. These isometries form the {\bf Poincar\'e group}
  $\bR^{1+3} \rtimes \SO(1,3)$. The subgroup $\SO(1,3)$ is known as
  the {\bf Lorentz group}; its elements are called {\bf Lorentz
    transformations}, and are precisely the isometries leaving the
  origin fixed.
\end{axiom}

So any Hamiltonian, Lagrangian, or physical expression we write down
from now on had better be Lorentz invariant (we will usually work
locally with nicely-behaved objects that are automatically invariant
under the full Poincar\'e group if they are Lorentz invariant).

Along with special relativity, Einstein introduced his {\bf summation
  notation} for tensors:
\begin{itemize}
\item Components of (contravariant) vectors $\vec{v}$ are written with
  superscripts, i.e. $\vec{v} = v^1 e_1 + \cdots + v^n e_n$, and those
  of (covariant) covectors with subscripts;
\item An index which appears both as a subscript and a superscript is
  implicitly summed over, i.e. $\vec{v} = v^i e_i$;
\item Unbound indices (the ones not summed over) must appear on both
  sides of an equation.
\end{itemize}
For example, $T^{\mu \alpha} = g^{\mu \nu} T^\alpha_\nu$ demonstrates
contraction with the metric tensor. When there is superscript that
should be a subscript, or vice versa, the metric tensor is implicitly
being used to raise and lower indices.

There are several conventions regarding Einstein's summation notation.
Spacetime variables are indexed by Greek letters, e.g. $\mu$ or $\nu$,
which run from $0$ to $3$, while space-only variables are indexed by
Roman letters, e.g. $i$ or $j$, which run from $1$ to $3$. Given a
$4$-vector $v = v^\nu e_\nu$, we let $\vec{v} = v^i e_i$ be the
space-only component, and $v^2$ generally denotes $v^\mu v_\mu$
whereas $\vec{v}^2$ generally denotes $v^i v_i$.


\chapter{Klein-Gordon Field}

In this chapter, we will look at our first quantum field, called the
Klein-Gordon field. This field arises from the Klein-Gordon equation
$$ (\partial^2 + m^2)\phi = 0, $$ which came about as an attempt to
make the Schr\"odinger equation compatible with special relativity,
where time and space coordinates can be mixed by Lorentz
transformations. Klein and Gordon first proposed it to describe
wavefunctions of relativistic electrons, but that interpretation
turned out to have some serious problems; nowadays we know it instead
describes a quantum field. Although it is meaningless classically
(i.e. it does not describe any classical system worth investigating),
we will begin by examining Klein-Gordon fields classically, and then
putting them through a process called canonical quantization to obtain
the quantum Klein-Gordon field.

\section{Why Fields?}

Before we begin, let's motivate why we want to look at fields instead
of wavefunctions. Why complicate things if we can do relativistic QM
with wavefunctions, instead of QFT with quantum fields?

%   Words of wisdom from Landau and Lifshitz: uncertainty principle implies
%   impossibility of wavefunction (see IV~\S~1, Landau Peierls~1931);
%   second quantization -- pick complete basis, count the number of
%   particles in each state..

    Volume 1 of Steven Weinberg's \emph{Quantum Theory of Fields} is
    devoted to answering this question. A discussion of scattering
    experiments lead him to the $S$-matrix, and then to the local behaviour
    of experiments (which he calls the cluster decomposition principle),
    and then using Lorentz invariance, fields just practically fall out.
    Weinberg does a really good job of convincing us that QFT in some form
    or another really must exist if we assume Lorentz invariance and
    unitarity.
%   First, he analyzes scattering
%   experiments and introduces us to the arena of the multiparticle Hilbert
%   space and the main player, the $S$-matrix. Next, using the cluster
%   decomposition principle, he justifies why a Hamiltonian must be written
%   as a sum of creation and annihilation operators. This cluster
%   decomposition principle makes precise what we mean by ``experiments at
%   large distances between one another are uncorrelated.'' Moreover, ``this
%   cluster decomposition principle plays a crucial part in making field
%   theory inevitable.'' (Weinberg Vol 1) This approach is very appealing
%   for it justifies why fields are important without citing the
%   ``problems'' of previous theories.
%
%   Miscelleanous remarks from the wisdom bank of Weinberg:
%   \begin{itemize}
%       \item {\color{red}``The structure and properties of any quantum field are
%           dictated by the representations of the homogenous Lorentz group
%       under which it transforms.''}
%       \item Free fields $\leftrightarrow$ trivial
%           representation, causal vector $\leftrightarrow$ 4-vector
%           representation, Dirac fields $\leftrightarrow$ dirac
%           representation, etc.
%   \end{itemize}

Peskin and Schroeder give a slightly different motivation, one that is
closer to the historical reason of why fields were introduced. There
are three main factors at play here.
\begin{itemize}
\item
  Single particle relativistic wave functions have unavoidable
  negative energy eigenstates. As an example, we can look at the Dirac
  equation. The Dirac equation comes from forcing the Schr\"odinger
  equation $i(d\Psi/dt) = \hat{H}\Psi$ to be Lorentz invariant. As it
  stands, it is first-order in time, but second-order in space.
  Suppose instead that
  $$ \hat{H} = \frac{1}{i} \alpha^j \partial_j + m\beta. $$
  Since $E^2 = \vec{p}^2 + m^2$, we want $\hat{H}^2 = -\nabla^2 + m^2$,
  which gives
  $$ \alpha^j \alpha^k + \alpha^k \alpha^j = 2\delta^{jk}, \quad
  \alpha^j \beta + \beta \alpha^j = 0, \quad \beta^2 = 1. $$
  Hence $\{\alpha^1, \alpha^2, \alpha^3, \beta\}$ are not scalars, but
  instead are the generators of a Clifford algebra; we take their
  simplest representation as matrices, which is as $4 \times 4$
  complex matrices
  $$ \alpha^j = \begin{pmatrix} 0 & \sigma_j \\ \sigma_j &
    0 \end{pmatrix}, \quad \beta = \begin{pmatrix} I & 0 \\ 0 &
    -I \end{pmatrix}, $$
  where $\sigma_j$ are the Pauli matrices. Now compute in momentum-
  space that
  $$ \widehat{H\psi}(\vec{p}) = (-i \vec{p} \cdot \vec{\alpha} +
  m\beta) \hat{\psi}(\vec{p}) = \begin{pmatrix} mI & \vec{p} \cdot
    \vec{\sigma} \\ \vec{p} \cdot \vec{\sigma} & -mI \end{pmatrix}
  \hat{\psi}(\vec{p}), $$
  and a straightforward calculation shows that $\hat{H}$ has
  eigenvalues $\pm \sqrt{\vec{p}^2 + m^2}$. In particular, the energy
  can be negative!

  Dirac attempted to resolve this issue by appealing to the Pauli
  exclusion principle and positing that there existed a whole ``sea of
  negative-energy states'' that were already occupied. Consequently,
  the holes in this sea would be antiparticles. This makes sense until
  we realize that that a particle falling into a negative-energy state
  would represent particle-antiparticle annihilation, but the Dirac
  equation is supposed to be modeling a single particle (an electron,
  actually). So philosophical issues aside, there are technical issues
  here. The field viewpoint will allow us to view particles as
  excitations of some field, and antiparticles of different types of
  excitations of the same field, but the key here is that these
  excitations all have positive energy, regardless of whether they
  represent particles or antiparticles. We will investigate this later
  on, when we see the Dirac field (which will contain the first
  non-trivial example of antiparticles).

\item
  $E=mc^2$ allows for particles to be created at high energies, and
  $\Delta E \Delta t = \hbar$ allows for virtual particles. This
  indicates we should really be looking at multi-particle instead of
  single-particle theories. While we can obtain multi-particle
  theories simply by looking at the tensor product of single-particle
  state spaces, the quantum mechanics arising from this construction
  do not permit the creation and annihilation of particles. We can't
  ``destroy'' or ``create'' a wavefunction; it exists for all time and
  space. Instead, the field viewpoint allows us to view particles as
  excitations of a field, which we can easily create or destroy.
  
\item
  Wavefunctions and quantum mechanics don't care about special
  relativity. In particular, there is obvious causality violation in
  quantum mechanics! Set $H = \FR{\hp^2}{2m}$ to be the free
  Hamiltonian, and let's compute the probability amplitude for
  propagation between two points $x_0$ and $x$ in spacetime:
  \begin{align*}
    U(t) &= \braket{\vec x|e^{-iHt}|\vec x_0}\\ &= \int
    \FR{d^3p}{(2\pi)^3} \braket{\vec
      x|e^{-i(p^2/2m)t}|p}\braket{p|x}\\ &= \int \FR{d^3p}{(2\pi)^3}
    e^{-i(p^2/2m)t}e^{i\vec p\cdot (\vec x-\vec x_0)}\\ &=
    \PFR{m}{2\pi i t}^{3/2} e^{im(\vec x-\vec x_0)^2/2t}
  \end{align*}
  This last quantity is non-zero, even for $x$ and $x_0$ that may be
  space-like separated, e.g. $x$ inside the light cone, and $x_0$
  outside it, which, in principle, allows faster-than-light transfer
  of information.

  It is not clear immediately how field theory will help us here. But
  we will see that by rigorously enforcing Lorentz invariance when we
  write down field dynamics, the causality violation problem magically
  disappears.
\end{itemize}

Another important reason we want to do QFT is because, well, the
theory predicts the outcome of numerous experiments to very high
accuracy. In the end, physics is about constructing models: the fact
that your model is giving good predictions is very strong evidence
that it should be adopted, or at least seriously considered as a
foundational theory. In particular, quantum electrodynamics (QED),
which describes electromagnetism, is something we will see very soon
that has been very well tested and agrees very well with experiments,
up to the limits of what we can experimentally measure.
    
\section{Elements of Classical Field Theory}

Before we embark on the long journey through QFT, we need to review
some tools from classical field theory first. This serves not only as
a review, but as motivation for many calculations and objects we will
be examining in the QFT world.

\subsection{Lagrangian Field Theory}

\begin{itemize}
\item Fundamental quantity in Lagrangian field theory is the action $S$.
In high school, the Lagrangian is a function of time,
positions, and velocities of a system: $L(t,x(t),\dot x(t))$. The action
is given by $S = \int dt\, L$.
Fields can also be described in a Lagrangian formalism, for instance by
considering every point in space-time as a ``particle'' that wiggles back
and forth with the amplitude of wiggling characterizing the strength of the
field.

Let $\vphi : M \to \bR$, define a Lagrangian \emph{density} $\mc
L(t,\vphi,\di_\mu \vphi)$, the honest Lagrangian $L = \int d^3x \mc L$, and
finally define the action: \[ S = \int dt\, L = \int d^4x \mc L \]

\begin{mdframed}
    Four-vector notation:
    \begin{itemize}
        \item Greek letters $\mu,\nu,\ldots \in \{0,1,2,3\}$
        \item Roman letters $i,g,\ldots \in \{1,2,3\}$.
        \item $x^\mu = (x^0,x^1,x^2,x^3)$
        \item Signature $(+---)$
        \item $\eta_{\mu\nu} = \mathrm{diag}(1,-1,-1,-1)$
        \item $\di_\mu f = \FR{\di f}{\di x^\mu} = (\di_0 f,\di_1 f,\di_2
            f,\di_3 f)$.
    \end{itemize}
\end{mdframed}

\item Extremize the action. Let $\delta f = f(\vphi+\xi) - f(\vphi)$.
    \begin{align*}
        0 = \delta S &= \int d^4 x \left( \ddi{\mc L}{\vphi}\delta\vphi
        +\ddi{\mc L}{(\di_\mu \vphi)}
        \underbrace{\delta(\di_\mu}_{\text{commute}}\vphi)\right)\\
        &= \int d^4 x \left[ \ddi{\mc L}{\vphi}\delta\vphi
        + \di_\mu \left(  \ddi{\mc L}{(\di_\mu\vphi)}\delta\vphi \right)
    - \di_\mu \left(\ddi{\mc L}{(\di_\mu\vphi)}\right)\delta\vphi \right]
    \end{align*}
    By Stokes' theorem, we can break this integral up into two parts, one
    of which is called the boundary term. Taking a variation that is fixed
    along the boundary means $\delta\vphi \equiv 0$ on the boundary which
    means that the boundary term does not contribute to $\delta S$.
    Moreover, if we take $\delta S = 0$ for every variation, then we obtain
    the Euler Lagrange equations:
    \[ \di_\mu \left( \ddi{\mc L}{(\di_\mu \vphi)} \right) - \ddi{\mc
    L}{\vphi} = 0 \]

    \begin{remark}
        The Lagragian formalism is useful for relativistic dynamics because
        all expressions are chosen to Lorentz invariant.
    \end{remark}
    \end{itemize}
\subsection{Hamiltonian Field Theory}
    \begin{itemize}
\item Introducing this makes the transition to the quantum theory easier.
\item High school Hamiltonian formalism: 
    $p = \ddi{L}{\dot q},H=\sum p\dot q-L$.
\item Pretend that $\vec x$ enumerates points on the lattice of space-time:
    \begin{align*}
        p(\vec x) = \ddi{\mc L}{\dot\vphi(\vec x)}
        &= \ddi{}{\dot\vphi(\vec x)}\int d^3y\, \mc
        L(\vphi(y),\dot\vphi(y))\\
        &\sim \ddi{}{\dot\vphi(\vec x)}\sum \mc
        L(\vphi(y),\dot\vphi(y)) d^3y\\
        &= \ddi{\mc L}{\dot\vphi(\vec x)} d^3x\\
        &\equiv \pi(\vec x)d^3 x
    \end{align*}
    since each point on the lattice represents a different variable, so the
    derivative just picks out the one at $\vec x$. We call $\pi(\vec x)$
    the momentum \emph{density}. Therefore the Hamiltonian looks like:
    \[H = \int d^3x\, \left[\pi(\vec x)\dot\vphi(\vec x) - \mc L\right].\]
    (See the stress-energy tensor part for another derivation of the
    Hamiltonian which falls out of Noether's theorem for being the
    conserved quantity under time translations.)
    
    One might ask why we are still singling out the time-parameter in
    the Hamiltonian formalism when we write $p(\vec{x}) = \partial \mc
    L/\partial \dot\vphi(\vec x)$ instead of making it seem more
    Lorentz invariant by considering $\partial \mc
    L/\partial(\partial_\mu \vphi(\vec x))$ instead. This is because
    although special relativity dictates that time transforms with
    space, we still cannot treat them equally as coordinates. The
    Hamiltonian is, by definition, the infinitesimal generator of time
    translations, and hence is intrinsically associated with only the
    time coordinate. In fact, it is not true that the Hamiltonian
    density is always Lorentz invariant.
    
\item \textbf{Important example:} Take $\mc L = \FR{1}{2}(\di_\mu\vphi)^2 -\FR{1}{2}
    m^2\vphi^2$. Euler-Lagrange equations become $\di^\mu(\di_\mu
    \vphi)+m^2\vphi=0$ which is the Klein Gordon equation. The Hamiltonian
    becomes:
    \[ H = \int d^3x \mc H
= \int d^3x \left[ \underbrace{\FR{\pi^2}{2}}_{\text{moving in time}}
    + \underbrace{\FR{(\nabla \vphi)^2}{2}}_{\text{shearing in space}}
+ \underbrace{\FR{m^2\vphi^2}{2}}_{\text{existing at all}}\right]\]
    \end{itemize}
    
\subsection{Noether's Theorem - How to Compute Conserved Quantities}
To every continuous transformation of the field we can assign an infinitesmal
transformation:
\[ \vphi(x) \rightarrow \vphi'(x) = \vphi(x) +
\alpha\underbrace{\Delta\vphi(x)}_{\text{deformation}}\]
Transformations might also change the Lagrangians. The interplay between
how the infinitesmal transformation changes the Lagrangian and the field is
what gives rise to conserved quantities, or sometimes known as Noether charges.
\begin{align*}
    \text{Symmetry} &\iff \text{Equations of motion -- invariant}\\
    &\iff \text{Action invariant (up to surface term)}\\
    &\iff \mc L(x) \rightarrow \mc L(x) + \alpha\di_mu \mc J^\mu(x)
\end{align*}
Taylor expanding the perturbation:
\begin{align*}
    \Delta \mc L &= \ddi{\mc L}{\vphi} \cdot \Delta \vphi + \ddi{\mc
    L}{(\di_\mu\vphi)}\di_\mu(\Delta\vphi)\\
    &= \di_\mu\left( \ddi{\mc L}{(\di_\mu\vphi)}\Delta\vphi \right) +
    \left[ \ddi{\mc L}{\vphi} - \di_\mu \left( \ddi{\mc L}{(\di_\mu \vphi)}
    \right) \right]\\
    &= \di_\mu\left( \ddi{\mc L}{(\di_\mu\vphi)}\Delta\vphi \right)\\
\end{align*}
Since we claimed that under the symmetry $\Delta\mc L = \di_\mu \mc J^\mu$
we have the following relations:
\begin{align*}
    j^\mu(x) &= \ddi{\mc L}{(\di_\mu\vphi)}\Delta\vphi - \mc J^\mu\\
    \di_\mu j^\mu &= 0\\
    \ddi{}{t} j^0 &= \di_i j^i
\end{align*}
Define the charge $Q = \int d^3x\; j^0$. Then, if we assume that space does
not have boundary, Stokes' theorem implies that $\di Q/\di t = 0$. Often,
$j^0$ is called the charge density, and $j^\mu$ is called the current
density.

%   \begin{mdframed}
%   Therefore to compute a conserved quantity we compare the deformation of the
%   Lagrangian due to the $\vphi$ changing with the deformation of the
%   Lagrangian due to the symmetry transformation. 
%   \end{mdframed}

\textbf{Examples:}
\begin{enumerate}
    \item $\mc L = \FR{1}{2}(\di_\mu \vphi)^2$ has the following field
        symmetry, $\vphi \to \vphi+\alpha$, ie. $\Delta\vphi \equiv$ const.
        There is no change to the Lagrangian, so $j^\mu = \di^\mu \vphi$.
    \item Space-time transformation, $x^\mu \to x^\mu-a^\mu$, implies
        \begin{align*}
        \vphi(x) &\to \vphi(x+a) = \vphi(x) + a^\nu\di_\nu\vphi(x)\\
        \mc L(x) &\to \mc L(x+a) = \mc L(x) + a^\mu\di_\mu \mc L\\
                 &. \quad\qquad\qquad = \mc L(x) +
                 a^\nu\di_\mu(\delta^\mu_\nu \mc L)
        \end{align*}
        Therefore we write 
        \[T^\mu_\nu = \ddi{\mc L}{(\di_\mu\vphi)}\di_\nu\vphi -
        \delta^\mu_\nu\mc L\]
        we get four separately conserved quantities.

        This is called the {\bf stress-energy tensor} or the {\bf
          energy-momentum tensor} in various contexts. The $T^{\bullet
          0}$ quantity gives rise to the Hamiltonian:
        \begin{align*}
            \int d^3x T^{00} = \int d^3x \mc H \equiv H
        \end{align*}

\end{enumerate}

%   \subsection{Summary of Computing Noether Charges}
%   Field or coordinate transformation $\leadsto$ $\{\Delta\phi,\Delta\mc L\}$
%   $\leadsto j^\mu(x) = \ddi{\mc L}{(\di_\mu\vphi)}\Delta\vphi - \mc J^\mu$
%   $\leadsto Q = \int j^0 d^3x$ conserved charge.

\section{Quantizing the Klein-Gordon Field}

Before we quantize, let's apply the classical theory to the classical
Klein-Gordon field, which is defined by the Lagrangian
$$ \cL = \frac{1}{2} \dot\phi^2 - \frac{1}{2} (\nabla \phi)^2 -
\frac{1}{2} m^2 \phi^2 = \frac{1}{2} (\partial_\mu \phi)^2 -
\frac{1}{2} m^2 \phi^2, $$ where $\phi(\vec{x})$ is the real-valued
     {\bf classical Klein-Gordon field}. We will interpret $m$ as a
     mass later on, but for now it is just a parameter.

\begin{exercise}
  By applying Euler-Lagrange, confirm that this Lagrangian for the
  classical Klein-Gordon field indeed gives the Klein-Gordon equation
  $(\partial^\mu \partial_\mu + m^2)\phi = 0$, and compute the
  Hamiltonian
  $$ H = \int d^3x \, \cH = \int d^3x \, \left(\frac{1}{2} \pi^2 +
  \frac{1}{2}(\nabla \phi)^2 + \frac{1}{2} m^2\phi^2\right). $$ (You
  should get that $\pi = \dot \phi$).
\end{exercise}

Now we enter the QFT world. For now we will work in the Schr\"odinger
picture, where $\phi(\vec x)$ and $\pi(\vec y)$ are time-independent.
We will take the classical Klein-Gordon field and {\bf canonically
  quantize} it, which involves two steps:
\begin{enumerate}
\item promote $\phi$ and $\pi$ to operators (i.e. $\phi(\vec{x})$ and
  $\phi(\vec{y})$ are now operators, not scalars), and
\item specify the commutation relations
  \begin{align*}
    [\phi(\vec x),\pi(\vec y)] &= i\delta^{(3)}(\vec x-\vec y)\\
    [\phi(\vec x),\phi(\vec y)] &= [\pi(\vec x),\pi(\vec y)] = 0.
  \end{align*}
  This is in analogy with the QM of a multiparticle system, where if
  $q_i$ and $p_i$ are the momentum and position operators of the
  $i$-th particle, then
  \begin{align*}
    [q_i, p_j] &= i\delta_{ij}\\
    [q_i, q_j] &= [p_i, p_j] = 0,
  \end{align*}
  except now we have a continuum of particles, indexed by the
  continuous variable $\vec{x}$ instead of a discrete variable $i$.
\end{enumerate}
Note that these commutation relations are taken to be {\bf axioms}. At
this point one may wonder why we treat $\phi$ and $\pi$ as different
operators when $\pi = \dot\phi$ for Klein-Gordon. This is for the same
reason that $x$ and $\dot x$ are treated independently in classical
field theory: we abuse notation and write $(x, \dot x)$ as coordinates
on phase space, when really we should be writing $(x, p)$. But we
write $\dot x$ because we will always be evaluating objects on phase
space at $(x, \dot x)$.

But of course, imposing these axioms is easier said than done. What do
$\phi$ and $\pi$ look like?

Let us try to motivate the form of the expression for $\phi$ and its
conjugate $\pi$ in terms of creation and annihilation operators.
\footnote{Quibble: I don't like how it is done in Peskin. Why promote the
coefficients in the Fourier transform, and why do \emph{they} give rise to
the creation and annihilation operators. I think there might be a good
explanation out there already; Landau\& Lifshitz, and Weinberg (Chapter 5) seem to take
a good wack at the physics of this choice. Actually, in LL, the exposition
seems to have avoided some of the integral manipulations that happened in
Peskin and Schroeder.}

If we expand a solution to the Klein Gordon equation in a Fourier basis of
plane waves, then we see that we naturally have some variables that we can
quantize. What's more interesting is that the Klein Gordon equation gives
rise to precisely the harmonic oscillator example from first year quantum
mechanics. In terms of creation and annihilation operators, the first years
wrote $\hat q = \FR{1}{\sqrt{2\om}}(a+a^\dag)$, $\hat p =
\SFR{\om}{2}(a-a^\dag)$. Therefore we conjecture our fields have the
following form: \footnote{{\elaborate}}
\newcommand{\vp}{{\vec p}}
\newcommand{\vx}{{\vec x}}
\begin{align*}
\phi(\vx) &= \int \FR{d^3p}{(2\pi)^3} \FR{1}{\sqrt{2\om_p}} (a_\vp e^{i\vp\cdot\vx} + a_\vp^\dag e^{-i\vp\cdot\vx})\\
\pi(\vx) &= \int \FR{d^3p}{(2\pi)^3}(-i)\SFR{\om_p}{\sqrt2} (a_\vp e^{i\vp\cdot\vx} - a_\vp^\dag e^{-i\vp\cdot\vx})
\end{align*}

\chapter{Dirac Field}
The formalism that we have built up so far tells that everything starts
from a Lagrangian. In the theory of elementary particles and high energy
physics there is one very special condition that we require of a
Lagrangian: Lorentz invariance. To check whether a given expression of
$\phi$'s and $\di_\mu\phi$'s is Lorentz invariant we must understand how
arbitrary field transform under the Lorentz group. Suppose a field has
components $\phi_a$, then a general transformation is given by
\[ \phi_a'(x) = M(\Lambda)_{ab}\phi_b(\Lambda^{-1}x). \]
Thus, to solve the problem of constructing all Lagrangians we must first
understand the representations of the Lorentz group, or at least of the
Lorentz algebra. Taking a cue from the $\so(3)$ generators given by
$J^{ij}=-i(x^i\di^j-x^j\di^i)$ it turns out that the generators for the
Lorentz algebra are:
\[ J^{\mu\nu} = i(x^\mu\di^\nu-x^\nu\di^\mu).\]
This gives commutation relations
\[ [J^{\mu\nu},J^{\rho\sg}] = \dots .\]
The defining representation is given by the following$(\mc
J^{\mu\nu})_{ab} = -i\delta^\mu_{[a}\delta^\nu_{b]}
=-i(\delta^\mu_{a}\delta^\nu_{b} -\delta^\mu_{b}\delta^\nu_{a})$
Dirac came up with another representation by taking 4 $n\times n$ matrices
$\gam^\mu$ satisfying ${\gam^\mu,\gam^\nu} = 2g^{\mu\nu}\times
\iden_{n\times n}$ and defining:
\[ S^{\mu\nu} = \FR{i}{4}[\gam^\mu,\gam^\nu].\]
If we define $\sg = (\iden,\vec\sigma)$ and $\bar\sg = (\iden,-\vec\sg)$
then \[\gam^\mu = \begin{pmatrix}0&\sg^\mu\\\bar\sg^\mu&0 \end{pmatrix}\] satisfies
the commutation relations and gives rise to the \textbf{Dirac
representation}. Objects that transform under that transform under this
representation are called $4$-component Dirac spinors, or just \textbf{Dirac
spinors} for short. 

Taking $\bar\psi = \gam^0\psi^\dag$, the Dirac equation, Lagrangian are
given by:
\begin{align*}
    (i\gam^\mu\di_\mu - m)\psi &= 0\\
    \mc L_{\text{Dirac}} &= \bar\psi(i\gam^\mu\di_\mu-m)\psi
\end{align*}
The conjugate variable to $\psi$ is $i\psi^\dag$. Before quantizing we
solve the Dirac equation in plane waves, $u(p)e^{i\vec p\cdot
\vec x}$ and $v(p)e^{-i\vec p\cdot \vec x}$. After rewriting the Dirac
equation into a matrix equation it is not hard to see that arbitrary
solutions $u(p)$ and $v(p)$ are given by the following expressions:
\begin{align*}
    u^s(p) &= \sqrt{m}\begin{pmatrix} \sqrt{p\cdot \sg} \xi^s\\
                      \sqrt{p\cdot \sg} \xi^s\end{pmatrix}\\
    v^s(p) &= \sqrt{m}\begin{pmatrix} \sqrt{p\cdot \sg} \eta^s\\
                      -\sqrt{p\cdot \sg} \eta^s\end{pmatrix}
\end{align*}
where, for $s=1,2$, $\{\xi^s\}$ and $\{\eta^s\}$ are a basis for $\bC^2$
and $\sqrt{p\cdot \sg}$ is the square root of the positive eigenvalue of
the associated matrix. (Phew, what a mouthful!)


Finally, we quantize this theory by introducing the \textbf{anticommutation
relations} and rewriting $\psi$ and $\bar\psi$ using raising and lowering
operators
\begin{align*} 
\{\psi(x),\bar\psi(y)\} &= \delta^{(3)}(\vec x-\vec y)\\
\psi(x) &= \int \FR{d^3p}{(2\pi)^3} 
\ha^{s\dag}_\vp u^s(\vp) e^{-i\vp\cdot\vx} -
\hb^{s\dag}_\vp v^s(\vp) e^{i\vp\cdot\vx} \\
\bar\psi(x) &= \int \FR{d^3p}{(2\pi)^3} 
\hb^{s\dag}_\vp \bar v^s(\vp) e^{-i\vp\cdot\vx} -
\ha^{s\dag}_\vp \bar u^s(\vp) e^{i\vp\cdot\vx}
\end{align*}
Using these cleverly chosen expressions we may write the Hamiltonian as
\begin{align*}
    H &= \int \FR{d^3p}{(2\pi)^3}  \sum_s
    E_\vp(\ha^{s\dag}_\vp\ha^{s}_\vp+ \hb^{s\dag}_\vp\hb^{s\dag}_\vp)\\
    Q &= \int \FR{d^3p}{(2\pi)^3}  \sum_s
    (\ha^{s\dag}_\vp\ha^{s\dag}_\vp - \hb^{s\dag}_\vp\hb^{s}_\vp)
\end{align*}
where $Q$ is the conserved quantity coming from gauge invariance,
$\psi'(x)=e^{\alpha(x)}\psi(x)$, of $\mc L_{\text{Dirac}}$.

\chapter{Path Integrals}

So far, we have taken classical field theories and canonically
quantized them to obtain the corresponding QFTs. In general, this
canonical quantization process is difficult and tedious, but it
motivates much of what we are about to do. The path integral approach
to QFT will allow us to perform perturbative calculations more easily,
and generalizes readily to other non-interacting theories. In
particular, for the entirety of this chapter, we will mostly be
concerned with calculating {\bf propagation amplitudes} for a
perturbed theory.

\section{Deriving the Path Integral}

Suppose we have the Hamiltonian $\hat{H}$ for a quantum mechanical
particle, and we want to compute the amplitude
$\braket{\vec{q}_b|e^{-i\hat{H}t}|\vec{q}_a}$, i.e. the amplitude for
the particle to travel from the point $\vec{q}_a$ to $\vec{q}_b$ in a
given time $t$. Using the superposition principle, let's compute this
by splitting up the time interval $[0, t]$ into $n$ equal chunks of
size $\delta t = t/n$:
$$ \braket{\vec{q}_b|e^{-i\hat{H}t}|\vec{q}_a} = \int \cdots \int d\vec{q}_1 \cdots d\vec{q}_{n-1} \braket{\vec{q}_b|e^{-i\hat{H}\delta t}|\vec{q}_{n-1}} \braket{\vec{q}_{n-1}|e^{-i\hat{H}\delta t}|\vec{q}_{n-2}} \cdots \braket{\vec{q}_1|e^{-i\hat{H}\delta t}|\vec{q}_a}. $$
What have we done? We are saying that the amplitude for propagation
from $\vec{q}_a$ to $\vec{q}_b$ is equal to the amplitude for
propagation from $\vec{q}_a$ to $\vec{q}_1$, then to $\vec{q}_2$, and
so on, until $\vec{q}_b$, integrated over all possible $\vec{q}_j$.
(Recall the double slit experiment and consider the case $n = 2$ if
you are still confused.)

Now each of the terms needs to be evaluated. For convenience, let
$\vec{q}_n = \vec{q}_b$ and $\vec{q}_0 = \vec{q}_a$. Let's do the
simple case where $\hat{H} = \hat{p}^2/2m$, a free particle. A
straightforward calculation shows:
\begin{align*}
  \braket{\vec{q}_{j+1}|e^{-i(\hat{p}^2/2m)\delta t}|\vec{q}_j}
  &= \int \frac{d^3p}{(2\pi)^3} \, \braket{\vec{q}_{j+1}|e^{-i(\hat{p}^2/2m)\delta t}|p}\braket{p|\vec{q}_j} \\
  &= \int \frac{d^3p}{(2\pi)^3} \, e^{-i(p^2/2m)\delta t} \braket{\vec{q}_{j+1}|p}\braket{p|\vec{q}_j} \\
  &= \int \frac{d^3p}{(2\pi)^3} \, e^{-i(p^2/2m)\delta t} e^{ip(\vec{q}_{j+1} - \vec{q}_j)}.
\end{align*}
Ah, we know how to evaluate this integral: it's just a Gaussian! The
final result, after some suggestive rearranging, is
$$ \braket{\vec{q}_{j+1}|e^{-i(\hat{p}^2/2m)\delta t}|\vec{q}_j} = \left(\frac{m}{2\pi i\delta t}\right)^{3/2} \exp\left(i\delta t \frac{m}{2}\left(\frac{\vec{q}_{j+1} - \vec{q}_j}{\delta t}\right)^2\right). $$
(The Gaussian integral itself is not trivial. \footnote{The relevant
formula is as follows. For $A \in \GL(n, \bC)$ such that $A = A^T$
and $\re A$ is positive semidefinite,
$$ \int d^nx \, e^{-Ax \cdot x/2 + iy \cdot x} = \frac{(2\pi)^{n/2}}{\sqrt{\det A}} e^{-A^{-1} y^2/2}. $$ 
One proves this by showing it first for $n = 1$ and $A = I$, in which
case it suffices to solve the DE
$$ \frac{d}{dy} \int dx \, e^{-x^2/2 + iyx} = -y \int dx \, e^{-x^2/2 + iyx}. $$
Now suppose $A$ is real and hence PSD. If we plug $x = \sqrt{A}v$ into
the LHS of the formula, the RHS splits as a product of one-dimensional
integrals, which we just calculated. Finally, since both sides are
analytic and agree for real PSD matrices, they agree in general.})
Hence when we plug this back into our calculation for
$\braket{\vec{q}_b|e^{-i\hat{H}t}|\vec{q}_a}$, we get
$$ \braket{\vec{q}_b|e^{-i\hat{H}t}|\vec{q}_a} = \left(\frac{m}{2\pi i\delta t}\right)^{3n/2} \int d\vec{q}_1 \cdots d\vec{q}_{n-1} \exp\left(i\delta t \frac{m}{2}\sum_{j=1}^{n-1} \left(\frac{\vec{q}_{j+1} - \vec{q}_j}{\delta t}\right)^2\right). $$
So far, everything we have done is rigorous. But now we make an
intuitive leap: instead of approximating the propagation from
$\vec{q}_a$ to $\vec{q}_b$ with a finite number of timesteps, we use
infinitely many. In other words, we ``integrate over paths'' by
letting $\delta t \to 0$ and $n \to \infty$, giving the formal
expression
$$ \braket{\vec{q}_b|e^{-i\hat{H}t}|\vec{q}_a} = \int D\vec{q}(t) \, \exp\left(i \int_0^t dt \, \frac{1}{2} m \vec{q}'(t)^2\right) $$
where the {\bf path integral} $\int D\vec{q}(t)$ is defined as
$$ \int D\vec{q}(t) = \lim_{n \to \infty} \left(\frac{m}{2\pi i\delta t}\right)^{3n/2} \int \cdots \int d\vec{q}_1 \cdots d\vec{q}_{n-1}. $$

\begin{exercise}
  Perform the same derivation of the path integral, but now starting with the Hamiltonian $\hat{H} = \hat{p}^2/2m + V(\hat{q})$. You should get
  $$ \braket{\vec{q}_b|e^{-i\hat{H}t}|\vec{q}_a} = \int D\vec{q}(t) \, \exp\left(i \int_0^t dt \, \frac{1}{2} m \vec{q}'(t)^2 - V(\vec{q}(t))\right). $$
\end{exercise}

For now, let's not worry about the infinite constant in front of the
path integral; it pales as an issue in comparison to the nonexistence
of a Lebesgue measure on the space of paths. Actually, the constant
will cancel out later.

Note that the integrand looks suspiciously like the Lagrangian
corresponding to the Hamiltonian in both cases. This is indeed true,
and can be demonstrated by plugging in a general Hamiltonian
$\hat{H}(\hat{q}, \hat{p})$ and seeing how combinations of $\hat{q}$
and $\hat{p}$ act on the $\ket{\vec{q}_i}$.

\begin{theorem}
  Suppose $\hat{H}(\vec{q}, \vec{p})$ is a {\bf Weyl-ordered}
  Hamiltonian, i.e. in a form where if there is a term
  $\vec{p}^{i_1} \vec{q}^{i_2} \cdots \vec{p}^{i_n}$, then there is a
  corresponding term
  $\vec{p}^{i_n} \vec{q}^{i_{n-1}} \cdots \vec{p}^{i_1}$. Then
  $$ \braket{\vec{q}_b|e^{-i\hat{H}t}|\vec{q}_a} = \int D\vec{q}(t) D\vec{p}(t) \, \exp\left(i \int_0^t dt \, \vec{p}(t) \cdot \vec{q}(t) - H(\vec{q}(t), \vec{p}(t))\right). $$
  In particular, for Hamiltonians quadratic in $\vec{p}$, we can
  integrate away the $\int D\vec{p}(t)$, leaving only the Lagrangian
  in the integrand.
\end{theorem}

\begin{proof}
  Details of the long calculation will not bring us much further
  enlightenment, so we omit them. See Peskin \& Schroeder, pages
  280-281 iff you like calculations and have some time to burn.
\end{proof}

Any Hamiltonian can be Weyl-ordered by commuting $\hat{p}$ and
$\hat{q}$, so this theorem is very general. In fact, it is general
enough that from now on, we will work directly with the Lagrangian and
almost completely ignore the Hamiltonian formalism. There is one major
advantage in doing so: the Lagrangian makes symmetries and
conservation laws very clear. For example, when we write down a
Lorentz-invariant Lagrangian, the path integral is automatically
Lorentz-invariant.

In fact, the quantum system we are considering is very general as
well. In our entire derivation of the path integral, we did not use
anything beyond the relationship between $\hat{q}$ and $\hat{p}$. So
in particular, our derivation holds not only for quantum mechanical
systems, but also for QFTs. For example, if we take the Lagrangian
$\cL = \frac{1}{2} (\partial_\mu \phi)^2 - V(\phi)$ for a real scalar
field, then
$$ \braket{\phi_b(\vec{x}) | e^{-i\hat{H}t} | \phi_a(\vec{x})} = \int D\phi(x) \, \exp\left(i \int_0^t d^4x \, \frac{1}{2} (\partial_\mu \phi)^2 - V(\phi)\right), $$
where here $D\phi(x)$ indicates that we are integrating over a path
taking values in fields. In particular, $\phi(0, \vec{x})$ is
constrained to be $\phi_a(\vec{x})$, and $\phi(t, \vec{x})$ is
constrained to be $\phi_b(\vec{x})$.

\section{Correlation Functions}

Okay, what good is the path integral? The answer is they are useful
when we apply perturbations to free field theory. Most of the QFT we
will be looking at is perturbative, so path integrals will give us a
good deal of physics. 

Suppose we have the Hamiltonian $\hat{H} = \hat{H}_0 + \hat{H}_{int}$,
where $\hat{H}_0$ is a Hamiltonian we are supposed to have understood
well already, and $\hat{H}_{int}$ is a perturbation known as the {\bf
  interaction Hamiltonian}. Usually $\hat{H}_0$ will be the
Hamiltonian for the free field theory, i.e. the Klein-Gordon
Hamiltonian. Let $\ket{\Omega}$ be the ground state of $\hat{H}$. We
are interested in computing the probability amplitude of a propagation
from $\vec{x}$ to $\vec{y}$, i.e.
$$ \braket{\Omega| \phi(x) \phi(y) | \Omega}. $$
How do we compute this quantity? Let's start with a
seemingly-unrelated quantity:
$$ \int D\phi(x) \, \phi(x_1) \phi(x_2) \exp\left(i \int_{-t}^t d^4x \, \cL(\phi)\right), $$
where the path $\phi(x)$ starts at some $\phi_a(\vec{x})$ at time $-t$
and ends at some $\phi_b(\vec{x})$ at time $t$. Suppose
$x_1^0 < x_2^0$. Then we are going to divide up this path integral
into three components:
\begin{enumerate}
\item from $\phi_a(\vec{x})$ at time $-t$ to $\phi_1(\vec{x})$ at time $x_1^0$, 
\item from $\phi_1(\vec{x})$ at time $x_1^0$ to $\phi_2(\vec{x})$ at time $x_2^0$,
\item from $\phi_2(\vec{x})$ at time $x_2^0$ to $\phi_b(\vec{x})$ at time $t$.
\end{enumerate}
Note that here, $-t < x_1^0 < x_2^0 < t$, and since the intermediate
field configurations $\phi_1(\vec{x})$ and $\phi_2(\vec{x})$ are
arbitrary, we must integrate over them as well. Hence the integral
becomes
$$ \int D\phi_1(\vec{x}) \int D\phi_2(\vec{x}) \, \phi_1(\vec{x}_1) \phi_2(\vec{x}_2) \braket{\phi_b | e^{-i\hat{H}(t - x_2^0)} | \phi_2}\braket{\phi_2 | e^{-i\hat{H}(x_2^0 - x_1^0)} | \phi_1}\braket{\phi_1 | e^{-i\hat{H}(x_1^0 - (-t))} | \phi_a}. $$
Now we use completeness:
$\int D\phi_1 \, \phi_1(\vec{x}_1) \ket{\phi_1}\bra{\phi_1} =
\phi_1(\vec{x}_1)$,
where the $\phi_1$ on the LHS is a scalar field, and on the RHS is an
operator. Doing the same for for $\phi_2$, the integrals disappear,
and some rearrangement gives
$$ \bra{\phi_b(\vec{x})} e^{-i\hat{H}(t - x_2^0)} \phi(\vec{x}_2) e^{-i\hat{H}(x_2^0 - x_1^0)} \phi(\vec{x}_1) e^{-i\hat{H}(x_1^0 - (-t))} \ket{\phi_a(\vec{x})}. $$
Aha, but
$\phi(x_2) = e^{i\hat{H}x_2^0}\phi(\vec{x}_2)e^{-i\hat{H}x_2^0}$ in
the Heisenberg picture, so this simplifies further to
$$ \bra{\phi_b(\vec{x})} e^{-i\hat{H}t} \phi(x_2)\phi(x_1) e^{-i\hat{H}t} \ket{\phi_a(\vec{x})}. $$
We're not done yet! During this calculation, we had to assume $x_1$
came before $x_2$ in time, so that the path integral split well. If
$x_1$ actually came after $x_2$, then we simply exchange $x_1$ and
$x_2$ in the final result. This motivates the following definition.

\begin{definition}
  Given two operators $\phi(x_1)$ and $\phi(x_2)$, the {\bf
    time-ordering operator} $T$ applies them in the correct temporal
  order, i.e.
  $$ T\{\phi(x_1)\phi(x_2)\} = \begin{cases} \phi(x_1)\phi(x_2) & x_1^0 > x_2^0 \\ \phi(x_2)\phi(x_1) & x_2^0 > x_1^0. \end{cases} $$
\end{definition}

Hence we should really be looking to calculate
$\braket{\Omega|T\phi(x_1)\phi(x_2)|\Omega}$, while right now we have
the quantity
$\bra{\phi_b(\vec{x})} e^{-i\hat{H}t} T\phi(x_2)\phi(x_1)
e^{-i\hat{H}t} \ket{\phi_a(\vec{x})}$.
In other words, our problem is to obtain $\ket{\Omega}$ from
$e^{-i\hat{H}t} \ket{\phi_a(\vec{x})}$. Physicists have a hilarious
trick for doing so. First expand $\ket{\phi_a}$ in the eigenbasis
$\{\ket{\Omega}, \ket{1}, \ldots\}$ of $\hat{H}$:
$$ e^{-i\hat{H}t} \ket{\phi_a} = e^{-iE_{\Omega}t} \ket{\Omega} \braket{\Omega|\phi_a} + \sum_{n>0} e^{-iE_nt} \ket{n} \braket{n|\phi_a}. $$
Now remember that the ground state energy is the lowest energy, i.e.
$E_\Omega < E_n$ for all $n > 0$. So here's what we do to keep the
$\ket{\Omega}$ term while getting rid of everything else: we take the
limit $t \to \infty(1 - i\epsilon)$. Since
$e^{-iE_n T(1 - i\epsilon)}$ will decay faster than
$e^{-iE_\Omega T(1 - i\epsilon)}$, because $e^{-E_n t}$ decays faster
than $e^{-E_\Omega t}$, it follows that when $T \to \infty$, every
other term except the $\ket{\Omega}$ term vanishes.
$$ \lim_{t \to \infty(1 - i\epsilon)} e^{-i\hat{H}t} \ket{\phi_a} = \braket{\Omega|\phi_a} e^{-E_\Omega \infty (1 - i\epsilon)} \ket{\Omega}. $$
It remains to get rid of the extraneous factors in the final
expression. Well that's easy, we just divide out by
$$ \bra{\phi_b} e^{-i\hat{H}t} e^{-i\hat{H}t} \ket{\phi_a} = \int D\phi(x) \, \exp\left(i \int_{-t}^t d^4x \, \cL(\phi)\right). $$

\begin{theorem}
  The amplitude for a propagation between spacetime points $x_1$ and
  $x_2$ is
  $$ \bra{\Omega} T\phi(x_1)\phi(x_2) \ket{\Omega} = \lim_{t \to \infty(1 - i\epsilon)} \frac{\int D\phi(x) \, \phi(x_1) \phi(x_2) \exp\left(i \int_{-t}^t d^4x \, \cL\right)}{\int D\phi(x) \, \exp\left(i \int_{-t}^t d^4x \, \cL\right)}. $$
\end{theorem}

This quantity is important enough to have a name: it is called the
{\bf two-point correlation function}. It is usually denoted
$\braket{\phi(x_1)\phi(x_2)}$ for convenience. Analogously, we have
{\bf $n$-point correlation functions}
$\braket{\phi(x_1) \cdots \phi(x_n)}$.

Since $\pm \infty(1 - i\epsilon)$ is ``a finite distance'' away from
$\pm \infty$, we usually write $\int_{-\infty}^\infty d^4x \, \cL$ in
the exponential. Better yet, we write $\int d^4x \, \cL$ and take it
to be understood that we are integrating over all spacetime now.

\section{The Generating Functional}

This formula for the propagation amplitude may not seem like much of
an improvement. But it is, and it will be obvious by the end of this
section how. Let's begin with the {\bf free-field Lagrangian}
$$ \cL = \frac{1}{2} (\partial_\mu \phi)^2 - \frac{1}{2} m^2\phi^2. $$
(Later on we will see why this is called the free field Lagrangian.)
If we plug this Lagrangian into the path integral, the integral is
directly computable; the end result is a Klein-Gordon field, which we
are already familiar with. So let's add a general perturbation term:
$$ \cL = \frac{1}{2} (\partial_\mu\phi)^2 - \frac{1}{2} m^2\phi^2 + J\phi, $$
where here $J(x)$ is a function of $x$, representing an {\bf
  excitation}, and usually called a {\bf source function}. The
resulting path integral is written
$$ Z[J] = \int D\phi \exp\left(i \int d^4x \, \frac{1}{2} (\partial_\mu \phi)^2 - \frac{1}{2}m^2\phi^2 + J\phi\right), $$
and called the {\bf generating functional}. In this notation, we want
to find $Z[J]/Z[0]$.

{\bf Note}: adding a source function is not the same thing as adding
an interaction. Source functions merely allow us to create sources and
sinks, whereas interactions allow the excitations generated by the
sources and sinks to interact with themselves. Here we are still
working within a free Klein-Gordon theory.

We can write $Z[J]$ in a very explicit form. First, let's rewrite the
Lagrangian a little via integration by parts:
$$ \int d^4x \, \frac{1}{2} (\partial_\mu \phi)^2 - \frac{1}{2} m^2\phi^2 + J\phi = \int_0^t d^4x \, \frac{1}{2} \phi(-\partial^2 - m^2)\phi + J\phi. $$
We will evaluate this a little informally, but the entire argument can
be made formal once we introduce the Green's function (the definition
of which will be motivated by this argument). Imagine that the
integral above is actually a giant sum,
$\phi = (\phi_1, \ldots, \phi_n)$ is merely a vector, and
$(-\partial^2 - m^2) = A$ merely an $n \times n$ matrix. Then $Z[J]$
becomes
$$ \int d\phi_1 \cdots \int d\phi_n \, \exp\left(\frac{i}{2} \phi^T A \phi + iJ\phi\right) = \left(\frac{(2\pi i)^n}{\det A}\right)^{\frac{1}{2}} \exp\left(-\frac{i}{2} JA^{-1}J\right). $$
Physicists call this process ``discretizing spacetime,'' which sounds
cooler.

Now we want to pass back into the continuum limit, i.e. replace $\phi$
as a vector with $\phi$ as a field, and $A$ with
$(-\partial^2 - m^2)$. But what should be replace $A^{-1}$ by? In the
discretized case, we had $AA^{-1} = I$, so by analogy, we should
replace $A^{-1}$ by a function $G(x - y)$ satisfying
$$ (-\partial^2 - m^2)G(x - y) = \delta(x - y). $$
Such a function $G(x - y)$ is a {\bf Green's function} for the linear
differential operator $(-\partial^2 - m^2)$. So we pause quickly to
introduce Green's functions and related objects.

\subsection{Green's Functions and Propagators}

\begin{definition}
  Given a linear differential operator $L(x)$ (acting on
  distributions), its {\bf Green's function} $G(x - y)$ satisfies
  $L(x)G(x - y) = -i\delta(x - y)$. Hence given a differential
  equation of the form $L(x)u(x) = f(x)$, we can compute
  $$ L(x) \int dy \, G(x - y)f(y) = \int L(x) G(x - y) f(y) \, dy = -i \int \delta(x - y) f(y) \, dy = -i f(x), $$
  so that $u(x) = i \int dy \, G(x - y) f(y)$ is a solution.
\end{definition}

For example, the defining property of the Green's function $G(x - y)$
for the Klein-Gordon operator $(\partial^2 + m^2)$ can be written in
momentum space:
$$ (\partial^2 + m^2) \int \frac{d^4p}{(2\pi)^4} e^{-ip(x-y)} \tilde{G}(p) = \int \frac{d^4p}{(2\pi)^4} e^{-ip(x-y)}. $$
Then it is easy to solve for $\tilde{G}(p)$. Equating the two
integrands,
$$ (\partial^2 + m^2) e^{-ip(x-y)} \tilde{G}(p) = (-p^2 + m^2) e^{-ip(x-y)} \tilde{G}(p) = -i e^{-ip(x-y)}, $$
so we can directly write
$$ G(x - y) = \int \frac{d^4p}{(2\pi)^4} e^{-ip(x-y)} \tilde{G}(p) = \int \frac{d^4p}{(2\pi)^4} e^{-ip(x-y)} \frac{i}{p^2 - m^2}. $$

Here we must pause for a moment: there is something wrong with this
integral. When we integrate over $p$, there are two singularities at
$p^0 = \pm E_{\vec p}$, so this integral diverges. That's okay, say
the physicists, let's just specify how we treat the poles, and write
down the following version of the Green's function:
$$ D_F(x - y) = \int \frac{d^4p}{(2\pi)^4} e^{-ip(x-y)} \tilde{G}(p) = \int \frac{d^4p}{(2\pi)^4} e^{-ip(x-y)} \frac{i}{p^2 - m^2 + i\epsilon}. $$
Now the poles are displaced above and below the real $p^0$ axis, at
$p^0 = \pm (E_{\vec p} - i\epsilon)$ in the ``complex $p^0$ plane'',
and we don't have divergence issues anymore. This version of the
Green's function is called the {\bf Feynman propagator}.

\begin{exercise}
  Let $\theta(x - y)$ be the {\bf Heaviside step function}, i.e. it is
  $1$ when $x > y$, and $0$ otherwise. Compute that
  $$ D_F(x - y) = \theta(x^0 - y^0) \int \frac{d^3\vec{p}}{(2\pi)^3} \frac{1}{2E_{\vec p}} e^{-ip(x-y)}\bigg|_{p^0 = E_{\vec p}} + \theta(y^0 - x^0) \int \frac{d^3\vec{p}}{(2\pi)^3} \frac{1}{2E_{\vec p}} e^{-ip(x-y)}\bigg|_{p^0 = E_{-\vec p}} $$
  by analytic continuation into the complex $p^0$ plane, and by
  closing the contour either in the upper half plane when $x^0 > y^0$,
  or in the lower half plane when $x^0 < y^0$.
\end{exercise}

Why is the Green's function $D_F(x - y)$ called a propagator? The
answer lies in computing the amplitude
$\braket{0|\phi(\vec x)\phi(\vec y)|0}$ for a particle to propagate
from a point $\vec{x}$ in space to another point $\vec{y}$ in space:
\begin{align*}
  \braket{0|\phi(\vec x)\phi(\vec y)|0} 
  &= \int \frac{d^3\vec{p}_1}{(2\pi)^3 \sqrt{2E_{\vec{p}_1}}} \int \frac{d^3\vec{p}_2}{(2\pi)^3 \sqrt{2E_{\vec{p}}}} e^{-i\vec{p}_1\vec{x}} e^{i\vec{p}_2\vec{y}} \braket{0|[a_{\vec{p}_1}, a^\dagger_{\vec{p}_2}]|0} \\
  &= \int \frac{d^3\vec{p}}{(2\pi)^3 (2E_{\vec p})} e^{-ip(x - y)}\bigg|_{p^0 = E_{\vec p}}.
\end{align*}
Hence we have
$$ D_F(x - y) = \theta(x^0 - y^0)\braket{0|\phi(\vec x)\phi(\vec y)|0} + \theta(y^0 - x^0)\braket{0|\phi(\vec y)\phi(\vec x)|0} = \braket{0|T\phi(\vec x)\phi(\vec y)|0}. $$
So the Feynman propagator is the two-point correlation function for
free field theory: it represents the amplitude for an excitation to
propagate between $\vec x$ and $\vec y$.

\subsection{Computing the Generating Functional}

Now that we know about Green's functions, let's return to computing
the generating functional $Z[J]$. Recall that we left off at passing
back into the continuum limit from the discretized path integral
$$ \int d\phi_1 \cdots \int d\phi_n \, \exp\left(\frac{i}{2} \phi^T A \phi + iJ\phi\right) = \left(\frac{(2\pi i)^n}{\det A}\right)^{\frac{1}{2}} \exp\left(-\frac{i}{2} JA^{-1}J\right). $$
Now we know what to replace $A^{-1}$ with: the Green's function
$-iD_F(x - y)$. Hence
$$ Z[J] = C \exp\left(-\frac{1}{2} \int d^4x \, d^4y \, J(x) D_F(x - y) J(y)\right) $$
for some constant $C$. What is $C$? It is $Z[0]$. We have proved the
following result.

\begin{proposition}
  Let
  $$ D_F(x - y) = \int \frac{d^4p}{(2\pi)^4} \frac{e^{ik(x-y)}}{k^2 - m^2 + i\epsilon} $$
  be the Feynman propagator. Then
  $$ Z[J] = Z[0] \exp\left(-\frac{1}{2} \int d^4x \, d^4y \, J(x) D_F(x - y) J(y)\right). $$
\end{proposition}

Using this formula, let's compute some of the terms in $Z[J]/Z[0]$.
Write
$$ W[J] = -\frac{1}{2} \int \int d^4x \, d^4y \, J(x) D_F(x - y) J(y), $$
so that 
$$ Z[J]/Z[0] = \exp(i W[J]) = \sum_{n=0}^\infty \frac{(iW[j])^n}{n!}. $$
The $n = 2$ term is therefore proportional to
$$ \int\int\int\int d^4x_1 \, d^4x_2 \, d^4x_3 \, d^4x_4 \, D_F(x_1 - x_2) D_F(x_3 - x_4) J(x_1) J(x_2) J(x_3) J(x_4). $$
How can we interpret this term physically? Well, recall that
$D_F(x - y)$ is the propagation amplitude between $x$ and $y$. So this
integral is, up to a constant, the amplitude for an excitation at
$x_2$ to propagate to $x_1$, and an excitation at $x_4$ to propagate
to $x_3$, where $x_1, x_2, x_3, x_4$ can range over all space. The
point is that the propagation from $x_2$ to $x_1$ does not affect the
propagation from $x_4$ to $x_3$ whatsoever: we can completely separate
the integrals. This is why we say
$\cL = \frac{1}{2}(\partial_\mu\phi)^2 - \frac{1}{2}m^2\phi^2$ is a
{\bf free field theory}: there are no terms that create interactions
between different excitations of the field!

For the free field Lagrangian, sometimes we can even explicitly
compute $W[J]$. For example, let's take $J(x) = J_1(x) + J_2(x)$ where
$J_i(\vec x) = \delta^{(3)}(\vec{x} - \vec{x}_i)$, to represent two
distinct time-independent excitations. Then $W[J]$ will contain terms
for $J_1J_1$, $J_2J_2$, and $J_1J_2$ and $J_2J_1$. We neglect the
first two, since $J_1J_1$ would be present in $W[J]$ regardless of
whether $J_2$ is present or not, and similarly for $J_2$; they
correspond to ``self-interaction'' and are not interesting. Let's look
at the other two terms:
\begin{align*}
  &-\frac{1}{2} \iint d^4x \, d^4y \, J_1(x) D_F(x - y) J_2(y) + J_2(x) D_F(x - y) J_1(y) \\
  &= -\frac{1}{2} \iint dx_1^0 \, dx_2^0 \, D_F(x_1 - x_2) + D_F(x_2 - x_1) \\
  &= -\iint dx_1^0 \, dx_2^0 \, \int \frac{dp^0}{2\pi} \, e^{ip^0(x_1^0 - x_2^0)} \int \frac{d^3p}{(2\pi)^3} \frac{e^{i\vec{p}(\vec{x}_1 - \vec{x}_2)}}{p^2 - m^2 + i\epsilon} \\
  &= \int dx_1^0 \int \frac{d^3p}{(2\pi)^3} \frac{e^{i\vec{p}(\vec{x}_1 - \vec{x}_2)}}{\vec{p}^2 + m^2 + i\epsilon}.
\end{align*}
Now we can do three things. First, isolate the $\int dx_1^0$; this
evaluates to $t$, the time over which we do our path integral. Second,
get rid of the $i\epsilon$ in the denominator; $\vec{p}^2 + m^2$ is
always positive, so there are no poles. Third, remember that $Z[J]$
for the free, {\bf unperturbed} theory is just
$$ Z[J] = \braket{0|e^{-i\hat{H}_0t}|0} = e^{-iE_0 t}, $$
so up to the constant $Z[0]$, we can equate $e^{-iE_0t}$ with
$e^{iW[J]}$. We already have a factor of $t$ in $W[J]$, so that
cancels, and we are left with
$$ E_0 = -\int \frac{d^3p}{(2\pi)^3} \frac{e^{i\vec{p}(\vec{x}_1 - \vec{x}_2)}}{\vec{p}^2 + m^2} < 0. $$
Whoa. What happened? We put two time-independent excitations on a
field, and the ground state energy decreased. There is an attractive
force between the two excitations!

\begin{exercise}
  We didn't finish the computation of $E_0$: do the integral to obtain
  $E_0 = -e^{-mr}/4\pi r$ where $r$ is the distance between
  $\vec{x}_1$ and $\vec{x}_2$.
\end{exercise}

{\bf Note}: it may be confusing that earlier, we said the free-field
theory is non-interacting, i.e. excitations do not interact, whereas
here we clearly have an interaction (an attractive force) between two
excitations. We must be careful what we mean by ``excitation''. An
{\bf excitation of the field $\phi$} is represented by a propagator
$D_F(x - y)$: we think of it as the exchange of a virtual particle
between $x$ and $y$. It is true that in free-field theory, two such
field excitations do not interact, as we showed earlier with the
$n = 2$ term of $Z[J]$. However, two excitations in the form of {\bf
  sources} and {\bf sinks} placed on the field, i.e. terms in $J(x)$,
are of course allowed to interact, via excitations of the field
$\phi$.

\section{Feynman Diagrams}

Okay, enough of free field theory; while it is interesting, it is
unphysical to expect that excitations do not interact with each other.
Let's move on to {\bf $\phi^4$ theory}, where the Lagrangian looks like
$$ \cL = \frac{1}{2} (\partial_\mu \phi)^2 - \frac{1}{2} m^2\phi^2 - \frac{\lambda}{4!} \phi^4. $$
The $\lambda$ is a {\bf coupling constant}, and dictates how strongly
the $\phi^4$ term impacts the free field theory. The generating
functional is now
$$ Z[J, \lambda] = \int D\phi \exp\left(i \int d^4x \, \frac{1}{2} (\partial_\mu \phi)^2 - \frac{1}{2}m^2\phi^2 - \frac{\lambda}{4!}\phi^4 + J\phi\right). $$
How shall we compute $Z[J, \lambda]$? We have no idea whether it can
be written in closed form. So the physicists do it perturbatively.

Let's consider a much easier problem to gain some insight: let $q$ be
a one-dimensional variable, and evaluate
$$ Z = \int_{-\infty}^\infty dq \, \exp\left(-\frac{1}{2} q^2 + \lambda q^4 + Jq\right). $$
We know how to do this integral for $\lambda = 0$: it would just be a
Gaussian. So expand it as a series
$$ Z = \int_{-\infty}^\infty dq \, e^{-q^2/2 + Jq} \left(1 + \lambda q^4 + \lambda^2 q^8 + \cdots\right). $$
How do we evaluate each individual term? Here's a trick:
$$ \int_{-\infty}^\infty dq \, e^{-q^2/2 + Jq} q^{4n} = \left(\frac{d}{dJ}\right)^{4n} \int_{-\infty}^\infty dq \, e^{-q^2/2 + Jq}, $$
and we know how to evaluate the remaining Gaussian integral! So
$$ Z = \left(1 + \lambda \left(\frac{d}{dJ}\right)^4 + \lambda^2 \left(\frac{d}{dJ}\right)^8 + \cdots\right) \int_{-\infty}^\infty dq \, e^{-q^2/2 + Jq}. $$

We can do the original path integral for $Z[J]$ using this trick, but
first we need to make sense of what $d/dJ$ means when $J(x)$ is a
function. Fortunately, mathematicians have done this for us already.

\begin{definition}
  Let $X$ be a space of functions, and $\Phi: X \to \bC$ a functional
  (not necessarily linear). The {\bf functional derivative}
  $\delta \Phi(f)/\delta f(x)$ is formally defined as
  $$ \frac{\delta\Phi(f)}{\delta f(x)} = \lim_{\epsilon \to 0} \frac{\Phi(f + \epsilon \delta_x) - \Phi(f)}{\epsilon}, $$
  where $\delta_x$ is a delta function with its pole at $x$. An
  important property is that
  $\delta f(x)/\delta f(y) = \delta^{(4)}(x - y)$.
\end{definition}

\begin{exercise}
  Show that
  $$ Z[J, \lambda] = Z[0, 0] \exp\left(-\frac{i}{4!}\lambda \int d^4w \, \left(\frac{\delta}{\delta J(w)}\right)^4\right) \exp\left(-\frac{1}{2} \int d^4x \, d^4y \, J(x) D_F(x - y) J(y)\right) $$
  by first extending the solution to the easier problem to multiple
  dimensions, and then ``infinite dimensions''. Then use the previous
  theorem, where we computed $Z[J, 0]$.
\end{exercise}

At last, we arrive at the reason for which we have been doing all
these calculations. Let's expand $Z[J, \lambda]$ in another way:
\begin{align*}
  Z[J, \lambda]
  &= \int D\phi \, e^{i \int d^4x \, \cL} \sum_{n=0}^\infty \frac{\left(i \int d^4x \, J(x)\phi(x) \right)^n}{n!} \\
  &= \sum_{n=0}^\infty \frac{1}{n!} \left(\int dx_1 \cdots dx_n \, J(x_1) \cdots J(x_n) \right) \left(\int D\phi \, \phi(x_1) \cdots \phi(x_n) e^{i \int d^4x \, \cL}\right).
\end{align*}
The second term looks oddly familiar. Indeed, it is (up to
normalization), the {\bf $n$-point correlation function}
$\braket{\phi(x_1)\cdots \phi(x_n)}$ that we wanted to compute from a
long time ago! So what the path integral has really given us is an
extremely easy way to perturbatively compute the $n$-point correlation
functions: we simply need to compute the coefficient of $J^n$, which
is a series in $\lambda$. Taking the first few terms
$\lambda^0, \lambda^1, \cdots$ will give an approximation to the
correlation function.

For example, the $\lambda^1 J^4$ term comes from
a $J^8$ term in $\exp(-(1/2)W[J])$ being differentiated by a
$\lambda^1$ term in the other exponential:
$$ \left(-\frac{i}{4!} \lambda \int d^4w \, \left(\frac{\delta}{\delta J(w)}\right)^4 \right)\left(\frac{1}{4! 2^4} \int d^4x_1 \cdots d^4x_8 \, J_1 J_2 J_3 J_4 J_5 J_6 J_7 J_8 D_{12} D_{34} D_{56} D_{78}\right), $$
where $J_n$ stands for $J(x_n)$, and $D_{ij}$ stands for
$D_F(x_i - x_j)$.

\begin{exercise}
  Do this computation. It is really not as bad as it looks: think of
  the action of $\partial/\partial J(w)$ as selecting one of the
  $J_i$'s, and setting its variable, i.e. $x_i$, to $w$. So applying
  $(\partial/\partial J(w))^4$ really just picks four different
  $x_i$'s and sets them to $w$. For example, we can pick
  $x_2, x_4, x_6, x_8$ to get a term proportional to
  $$ \lambda \int dw \, \int d^4x_1 \, d^4x_3 \, d^4x_5 \, d^4x_7 \, J_1J_3J_5J_7 D_{1w} D_{3w} D_{5w} D_{7w}. $$
  Note, however, there are many ways to get a term of this form. We
  could have picked any of the $4!$ permutations of
  $x_2, x_4, x_6, x_8$. Or any of the $4!$ permutations of
  $x_1, x_3, x_5, x_7$. Or we can substitute $1$ for $2$, or $3$ for
  $4$, etc. in any such choice. There are {\bf symmetry factors} for
  each term. Compute these carefully. You should get the result
  $$ \int_w \int\int\int\int J_1 J_2 J_3 J_4 \left(-i\lambda D_{1w} D_{2w} D_{3w} D_{4w} - \frac{i\lambda}{2} D_{12}D_{3w}D_{4w}D_{ww} - \frac{i\lambda}{8} D_{12} D_{34} D_{ww} D_{ww}\right). $$
\end{exercise}

As with the free field case, we can physically interpret each of these terms. For example, in the first term, excitations from $x_1, x_2, x_3, x_4$ are propagating from/to an interaction point $w$. In the second term, there is a {\bf self-interaction} from $w$ to $w$, and interactions between $x_1$ and $w$, $x_2$ and $w$, and $x_3$ and $x_4$. We can similarly interpret the third term. The point is that to each term we can associate a little pictorial diagram of what is physically happening:
\begin{center}
\begin{tikzpicture}[node distance=1.5cm and 1.5cm,scale=0.33]
\coordinate[label=left:$J_1$] (J1);
\coordinate[vertex,below right=of J1] (w);
\coordinate[above right=of w,label=right:$J_2$] (J2);
\coordinate[below left=of w,label=left:$J_3$] (J3);
\coordinate[below right=of w,label=right:$J_4$] (J4);
\begin{scope}[every node/.style={scale=.85}]
\draw[particle] (J1) -- node[label=left:$D_{1w}$] {} (w);
\draw[particle] (J2) -- node[label=right:$D_{2w}$] {} (w);
\draw[particle] (J3) -- node[label=left:$D_{3w}$] {} (w);
\draw[particle] (J4) -- node[label=right:$D_{4w}$] {} (w);  
\end{scope}
\end{tikzpicture}
\qquad
\begin{tikzpicture}[node distance=1.5cm and 1.5cm,scale=0.33]
\coordinate[label=left:$J_1$] (J1);
\coordinate[right=3cm of J1,label=right:$J_2$] (J2);
\coordinate[below=3cm of J1,label=left:$J_3$] (J3);
\coordinate[vertex,right=of J3] (w);
\coordinate[right=of w,label=right:$J_4$] (J4);
\begin{scope}[every node/.style={scale=.85}]
\draw[particle] (J1) -- node[label=above:$D_{12}$] {} (J2);
\draw[particle] (J3) -- node[label=above:$D_{3w}$] {} (w);
\draw[particle] (J4) -- node[label=above:$D_{4w}$] {} (w);
\draw[particle] (w) edge[loop above,in=60,out=120,min distance=7.5cm] node[label=right:$D_{ww}$] {} (w);
\end{scope}
\end{tikzpicture}
\qquad
\begin{tikzpicture}[node distance=1.5cm and 1.5cm,scale=0.33]
\coordinate[label=left:$J_1$] (J1);
\coordinate[right=3cm of J1,label=right:$J_2$] (J2);
\coordinate[below=3cm of J1,label=left:$J_3$] (J3);
\coordinate[right=3cm of J3,label=right:$J_4$] (J4);
\coordinate[vertex,below right=of J1] (w);
\begin{scope}[every node/.style={scale=.85}]
\draw[particle] (J1) -- node[label=above:$D_{12}$] {} (J2);
\draw[particle] (J3) -- node[label=above:$D_{34}$] {} (J4);
\draw[particle] (w) edge[loop,in=140,out=220,min distance=5cm] node[label=left:$D_{ww}$] {} (w);
\draw[particle] (w) edge[loop,in=-40,out=40,min distance=5cm] node[label=right:$D_{ww}$] {} (w);
\end{scope}
\end{tikzpicture}
\end{center}


\end{document}
